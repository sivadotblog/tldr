Stanford AI Index Report üìÉ, Google‚Äôs Infinite Context LLMs üìö, Megalodon Efficient Transformer Pretraining üåê

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2024-04-17

## Stanford AI Index Report üìÉ, Google‚Äôs Infinite Context LLMs üìö, Megalodon Efficient Transformer Pretraining üåê

### 

[### Fresh web data for LLM and RAG apps (Sponsor)](https://brave.com/search/api/?mtm_source=tldr-ai&amp;mtm_medium=newsletter&amp;mtm_campaign=search-api&amp;mtm_content=evergreen)

If you want to build AI applications with access to the web, you need to check out the [Brave Search API](https://brave.com/search/api/?mtm_source=tldr-ai&mtm_medium=newsletter&mtm_campaign=search-api&mtm_content=evergreen).

With a single API call, you'll get relevant search results from an [billions of webpages](https://brave.com/search/api/?mtm_source=tldr-ai&mtm_medium=newsletter&mtm_campaign=search-api&mtm_content=evergreen) ‚Äî high-quality, real-time data you can build on.

You can trust the results: Brave is the [fastest-growing search engine since Bing](https://brave.com/search/api/?mtm_source=tldr-ai&mtm_medium=newsletter&mtm_campaign=search-api&mtm_content=evergreen), and one of the only truly independent search providers.

Best of all, the Brave Search API is by far the least expensive option out there. It's [FREE for up to 2,000 monthly calls](https://brave.com/search/api/?mtm_source=tldr-ai&mtm_medium=newsletter&mtm_campaign=search-api&mtm_content=evergreen), with paid plans that start from $5.

[Get your free API key ‚ÜóÔ∏è](https://brave.com/search/api/?mtm_source=tldr-ai&mtm_medium=newsletter&mtm_campaign=search-api&mtm_content=evergreen)

üöÄ

### Headlines & Launches

[### Stanford HAI Releases 2024 AI Index Report (Website)](https://hai.stanford.edu/research/ai-index-report?utm_source=tldrai)

The Stanford Institute for Human-Centered AI has released its seventh annual AI Index report. This year's report covers the rise of multimodal foundation models, major cash investments into generative AI, new performance benchmarks, shifting global opinions, and new major regulations.

[### Apple iOS 18 Will Be On-Device (1 minute read)](https://appleinsider.com/articles/24/04/15/apples-ios-18-ai-will-be-on-device-preserving-privacy-and-not-server-side?utm_source=tldrai)

Apple's upcoming AI features in iOS 18 are rumored to focus on privacy, with the initial set of enhancements functioning entirely on-device without the need for an internet connection or cloud-based processing, thanks to the company's in-house large language model known internally as "Ajax."

[### Google's New Technique Gives LLMs Infinite Context (5 minute read)](https://venturebeat.com/ai/googles-new-technique-gives-llms-infinite-context/?utm_source=tldrai)

Google researchers have introduced Infini-attention, a technique that enables LLMs to work with text of infinite length while keeping memory and compute requirements constant.

üß†

### Research & Innovation

[### Compression represents intelligence linearly (18 minute read)](https://arxiv.org/abs/2404.09937?utm_source=tldrai)

Most modern AI is built around the idea of compressing a training dataset into a model. The better the compression, the better the model. This paper shows that relation rigorously and posits that scale benchmark scores correlate strongly to a model's ability to compress novel text.

[### Megalodon Efficient Transformer Pretraining (17 minute read)](https://arxiv.org/abs/2404.08801?utm_source=tldrai)

Another long context paper - this time, a new architecture that uses two novel weight updating schemes. It outperforms Llama 2 on the same number of training tokens 2T. It also scales to infinite context length at inference time.

[### Feedback in Transformers (24 minute read)](https://arxiv.org/abs/2404.09173?utm_source=tldrai)

TransformerFAM provides a feedback mechanism that allows Transformers to attend to their own latent representations. This can, in theory, introduce recurrence into the model for processing extremely long inputs in context.

üë®‚Äçüíª

### Engineering & Resources

[### Virtual Workshop: Fine-tune Your Own LLMs to GPT-4 Levels (Sponsor)](https://my.demio.com/ref/P4AKDf7qoJBjZla3?utm_medium=3rdparty&amp;utm_source=tldr)

The Predibase team recently launched LoRA Land, a collection of [25+ fine-tuned Mistral-7b models that rival GPT4](https://my.demio.com/ref/P4AKDf7qoJBjZla3?utm_medium=3rdparty&utm_source=tldr) on a set of task-specific applications. In this hands-on workshop, you'll learn how to [build your own](https://my.demio.com/ref/P4AKDf7qoJBjZla3?utm_medium=3rdparty&utm_source=tldr) LoRA Land with popular open-source LLM frameworks, Ludwig and LoRAX. Become a fine-tuning pro. [Join the live workshop on April 30](https://my.demio.com/ref/P4AKDf7qoJBjZla3?utm_medium=3rdparty&utm_source=tldr)

[### Enhanced Vision-Language Model (GitHub Repo)](https://github.com/congvvc/lasagna?utm_source=tldrai)

Vision Language Models (vLLMs) often struggle with processing multiple queries per image and identifying when objects are absent. This study introduces a new query format to tackle these issues, and incorporates semantic segmentation into the training process.

[### AI system that creates detailed, cited reports with retrieval (GitHub Repo)](https://github.com/stanford-oval/storm?utm_source=tldrai)

Stanford has released a neat research system called Storm that uses retrieval guided language models to create reports for specific topics.

[### Road Line Segmentation for Autonomous Driving (16 minute read)](https://arxiv.org/abs/2404.07626v1?utm_source=tldrai)

Accurately segmenting road lines and markings is crucial for autonomous driving but challenging due to occlusions caused by vehicles, shadows, and glare. The Homography Guided Fusion (HomoFusion) module uses video frames to identify and classify obscured road lines by leveraging a novel surface normal estimator and a pixel-to-pixel attention mechanism.

üéÅ

### Miscellaneous

[### Qwen Coder (12 minute read)](https://qwenlm.github.io/blog/codeqwen1.5/?utm_source=tldrai)

Code Qwen 1.5 is a new set of 7B models trained on 3T tokens of code related data. It performs well on HumanEval, with a non-zero score on SWE-bench. The chat variant specifically shows promise for long context retrieval tasks up to 64k tokens.

[### 1-bit Quantization (7 minute read)](https://mobiusml.github.io/1bit_blog/?utm_source=tldrai)

Extreme low-bit quantization for small pre-trained models, like Llama2-7B, is challenging, but fine-tuning just 0.65% of parameters significantly improves performance. Newly fine-tuned 1-bit models outperform 2-bit Quip# models, while 2-bit models with specialized data can exceed full-precision counterparts. This research suggests that proper fine-tuning and quantization may enhance efficiency without compromising model quality, potentially shifting focus from training smaller models to optimizing larger, quantized ones.

[### Accelerating AI: Harnessing Intel(R) Gaudi(R) 3 with Ray 2.10 (5 minute read)](https://www.anyscale.com/blog/accelerating-ai-harnessing-intel-gaudi-3-with-ray-2-10?utm_source=tldrai)

Anyscale's latest release of Ray, Ray 2.10, adds support for Intel Gaudi 3. Developers can now spin up and manage their own Ray Clusters, provisioning Ray Core Task and Actors on a Gaudi fleet directly through Ray Core APIs, tap into Ray Serve on Gaudi through Ray Serve APIs for a higher level experience, and configure Intel Gaudi accelerator infrastructure for use at the Ray Train layer.

‚ö°Ô∏è

### Quick Links

[### You can't do AI with failed data pipelines (Sponsor)](https://www.astronomer.io/ebooks/accelerate-ai-with-airflow/?utm_source=tldr-ai-newsletter&amp;utm_medium=email&amp;utm_campaign=ai-ebook)

Apache Airflow is playing a key role in the AI/ML initiatives of modern enterprises. Find out how to start delivering production-ready AI with Airflow in this [free ebook by Astronomer](https://www.astronomer.io/ebooks/accelerate-ai-with-airflow/?utm_source=tldr-ai-newsletter&utm_medium=email&utm_campaign=ai-ebook).

[### Limitless (Product)](https://www.limitless.ai/?utm_source=tldrai)

Personalized AI app and wearable powered by what you've seen, said, and heard.

[### Introducing ALOHA Unleashed (2 minute video)](https://twitter.com/tonyzzhao/status/1780263497584230432?utm_source=tldrai)

Google DeepMind's ALOHA Unleashed is a program that pushes the boundaries of dexterity with low-cost robots and AI.

[### Four steps for founders integrating AI (4 minute read)](https://foundationcapital.com/from-idea-to-integration-four-steps-for-founders-integrating-ai/?utm_source=tldrai)

The pressure is immense right now to have a plan to factor AI into existing products. This short step-by-step guide will help you take the first step.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590613