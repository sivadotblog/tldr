OpenAI ads üì∞, how prompt caching works üíª, context plumbing üìÑ

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2025-12-01

## OpenAI ads üì∞, how prompt caching works üíª, context plumbing üìÑ

### 

[### Your AI isn't built for marketing and digital teams. Opal is (Sponsor)](https://www.optimizely.com/insights/blog/why-opal-is-not-just-another-ai-tool-for-marketers/?utm_campaign=PS-GL-12-2025-TLDR&amp;utm_medium=cpc&amp;utm_source=tldr&amp;utm_content=opal-under-the-hood)

Heads up: If your go-to AI tool isn't purpose-built, you're bringing a spork to a swordfight.

[Optimizely Opal](https://www.optimizely.com/ai/?utm_campaign=PS-GL-12-2025-TLDR&utm_medium=cpc&utm_source=tldr&utm_content=opal-under-the-hood) is the agent orchestration platform built specifically for marketing and digital teams ‚Äì designed around real marketing pain points (\*cough\* lack of time cough), repetitive workflows, and the ‚ÄúI didn't sign up for this‚Äù tasks that kill momentum and creativity.

Opal turns marketing ideals into [always-on agents that do the work for you](https://www.optimizely.com/agents/?utm_campaign=PS-GL-12-2025-TLDR&utm_medium=cpc&utm_source=tldr&utm_content=opal-under-the-hood). Not another generic AI tool, but an AI system expressly designed for marketing teams.

What makes Opal different?

[Go under the hood of Optimizely Opal.](https://www.optimizely.com/insights/blog/why-opal-is-not-just-another-ai-tool-for-marketers/?utm_campaign=PS-GL-12-2025-TLDR&utm_medium=cpc&utm_source=tldr&utm_content=opal-under-the-hood)

üöÄ

### Headlines & Launches

[### OpenAI May Deploy Ads Soon (1 minute read)](https://x.com/btibor91/status/1994714152636690834?utm_source=tldrai)

A recent update to the ChatGPT Android app included references to an ‚Äúads feature‚Äù with ‚Äúsearch ads‚Äù and ‚Äúbazaar content‚Äù.

[### Claude 4.5 Opus' Soul Document (84 minute read)](https://www.lesswrong.com/posts/vpNG99GhbBoLov9og/claude-4-5-opus-soul-document?utm_source=tldrai)

There appears to be a document in the character training for Claude compressed within Claude's weights. While it is possible for the model to hallucinate the text, it appears to be real. This post details how the document was extracted. The full output of Claude's Soul Document is available in the post.

[### Databricks reportedly in talks to raise $5B at $134B valuation (3 minute read)](https://siliconangle.com/2025/11/30/databricks-reportedly-talks-raise-5b-134b-valuation/?utm_source=tldrai)

Databricks is reportedly in talks to raise $5 billion at a $134 billion valuation. The company has resisted pressure to go public, but an IPO would likely be well-received. Databricks has more than 20,000 customers, including OpenAI, Block, Shell, and Toyota. Its platform offers tools that support the full lifecycle of AI development, including feature engineering, model training, evaluation, and deployment.

üß†

### Deep Dives & Analysis

[### Are we in a GPT-4-style leap that evals can't see? (9 minute read)](https://martinalderson.com/posts/are-we-in-a-gpt4-style-leap-that-evals-cant-see/?utm_source=tldrai)

Chat is a terrible way to evaluate models. GPT-4 was so significantly better at answering questions that it was an obvious step forward. The industry needs to add more types of benchmarking. Models are currently being evaluated like students in an exam, but that's not representative of how the world works.

[### How prompt caching works (32 minute read)](https://sankalp.bearblog.dev/how-prompt-caching-works/?utm_source=tldrai)

Prompt caching works per-content, not per-conversation. Prefix caching works at the token level, not the request level, which is why it works across requests. Any change in the prefix breaks the entire hash chain.

üë®‚Äçüíª

### Engineering & Research

[### Forget the mythical 10x developers - focus on building 10x teams (Sponsor)](https://blog.sentry.io/the-dawn-of-the-10x-team/?utm_source=tldr&amp;utm_medium=paid-community&amp;utm_campaign=ai-fy26q4-evergreen&amp;utm_content=newsletter-10x-team-learnmore)

The 10x developer is a unicorn. But the 10x team? That's achievable ‚Äî when AI gives everyone the same context. [Sentry CEO's latest post](https://blog.sentry.io/the-dawn-of-the-10x-team/?utm_source=tldr&utm_medium=paid-community&utm_campaign=ai-fy26q4-evergreen&utm_content=newsletter-10x-team-learnmore) breaks down how AI agents are changing debugging from "here's what broke" to "here's why, explained in plain English." Shared reasoning means shorter feedback loops and compounding learning across the whole team. [Read the blog](https://blog.sentry.io/the-dawn-of-the-10x-team/?utm_source=tldr&utm_medium=paid-community&utm_campaign=ai-fy26q4-evergreen&utm_content=newsletter-10x-team-learnmore)

[### What makes a great ChatGPT app (10 minute read)](https://developers.openai.com/blog/what-makes-a-great-chatgpt-app?utm_source=tldrai)

The biggest mistake developers make is trying to port entire products into ChatGPT when they should instead expose a few powerful capabilities the model can orchestrate mid-conversation. Devs should organize around giving ChatGPT new data it can't access ("know"), enable real actions like booking appointments or playing games ("do"), and present information through richer UI than text walls ("show").

[### Embodied Cognition Benchmarking (4 minute read)](https://enact-embodied-cognition.github.io/?utm_source=tldrai)

ENACT is a benchmark for evaluating embodied cognition using egocentric world modeling.

[### Context plumbing (6 minute read)](https://interconnected.org/home/2025/11/28/plumbing?utm_source=tldrai)

Context is always changing, as it is dynamic. The context is not always where the AI runs. To make an agent run really well, you need to move the context to where it needs to be. Agents shouldn't have to look up context for every single query, because that's slow. Engineers need to build pipes that continuously flow potential context from where it is created to where it is going to be used.

üéÅ

### Miscellaneous

[### It's Hard to Feel the AGI (6 minute read)](https://tensorlabbet.com/2025/11/30/hard-to-feel-agi/?utm_source=tldrai)

Some of the most accomplished minds in AI are beginning to revise their projections for the near future. This may not be entirely unexpected for those who follow the field. LLMs and other generative models have undoubtedly made many tangible achievements. Discovering their limits remains a challenging task that could be lost if industry climate drops to a new 'AI winter'.

[### Vibe proving is here (1 minute read)](https://x.com/vladtenev/status/1994922827208663383?utm_source=tldrai)

An AI model just proved Erdos Problem #124 in Lean by itself. The problem has been open for nearly 30 years. The achievement shows how mathematical superintelligence is getting closer. The technology will change and dramatically accelerate progress in mathematics and all dependent fields.

‚ö°Ô∏è

### Quick Links

[### AI Adoption Rates Starting to Flatten Out (1 minute read)](https://www.apolloacademy.com/ai-adoption-rates-starting-to-flatten-out/?utm_source=tldrai)

This post contains charts that show how AI adoption rates are flattening out across all firm sizes.

[### The Thinking Game (Website)](https://thinkinggamefilm.com/?utm_source=tldrai)

The Thinking Game is a documentary that covers the pivotal moments over five years at DeepMind, an AI company founded by Demis Hassabis.

[### Inside Gemini 3 with Sundar Pichai (27 minute video)](https://www.youtube.com/watch?v=iFqDyWFuw1c&amp;utm_source=tldrai)

Google CEO Sundar Pichai reflects on the company's long-term AI strategy, the evolution of Gemini 3, and future bets like quantum computing in a conversation on the Google AI podcast.

## Get the most interesting AI stories and breakthroughs delivered in a free daily email.

Subscribe

Join 920,000 readers for [one daily email](/api/latest/ai)

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1764601652