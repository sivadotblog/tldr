DeepMind Alignment Research üìö, Brave Search AI üîç, Mistral Common üíª

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2024-04-22

## DeepMind Alignment Research üìö, Brave Search AI üîç, Mistral Common üíª

### 

[### üÜì Explore AI in Web Development with Netlify at Compose Web + AI (Sponsor)](https://www.netlify.com/compose/web-ai/?utm_campaign=Event-Compose-Web-AI&utm_source=email&utm_medium=tldr-newsletter&utm_content=tldr-newsletter)

AI is the biggest shift in web development in recent years ‚Äî on par with DevOps, headless, and composability.

Find out how to adopt [scalable AI strategies](https://links.tldr.tech/BFFend) and build teams that know how to use and measure its impact in this [free virtual event](https://links.tldr.tech/BFFend):

* Explore the future of [AI and the open web](https://links.tldr.tech/BFFend)
* Learn how to mitigate the risks of AI tools
* Get expert guidance on how AI is changing ecommerce
* Discover why [composability](https://links.tldr.tech/BFFend) is the foundation for AI transformation

[See the full agenda‚Äîincluding guest speakers‚Äîand join for free](https://links.tldr.tech/BFFend)

üöÄ

### Headlines & Launches

[### Updates from Google DeepMind Alignment research (8 minute read)](https://www.alignmentforum.org/posts/HpAr8k74mW4ivCvCu/progress-update-from-the-gdm-mech-interp-team-summary?utm_source=tldrai)

Following Anthropic, GDM has released some work from its alignment efforts. The main insightful piece here is using sparse autoencoders on Gemini Ultra. This is a substantial jump in interpretation size.

[### NVIDIA To Collaborate With Japan On Their Cutting-Edge ABCI-Q Quantum Supercomputer (2 minute read)](https://wccftech.com/nvidia-japan-abci-q-quantum-supercomputer/?utm_source=tldrai)

NVIDIA will power Japan's new quantum supercomputer, ABCI-Q, alongside Fujitsu, integrating 2,000 NVIDIA H100 AI GPUs and CUDA-Q platform for quantum-classical computing applications. The project aims to advance Japan's capabilities in quantum computing and AI. This collaboration is part of a broader technological partnership between NVIDIA and Japan.

[### Brave Search is adopting AI to answer your queries (2 minute read)](https://techcrunch.com/2024/04/17/brave-search-is-adopting-ai-to-answer-your-queries?utm_source=tldrai)

Brave Search has revamped its answer engine to include AI-synthesized responses worldwide, leveraging large language models and trusted data sources. The upgrade enables automatic or manual AI-enhanced answers to user queries. Brave acknowledges potential impacts on web publishers and plans to monitor and address the effects of AI-generated content on site traffic.

üß†

### Research & Innovation

[### Fine-tune Llama 3 with ORPO (13 minute read)](https://mlabonne.github.io/blog/posts/2024-04-19_Fine_tune_Llama_3_with_ORPO.html?utm_source=tldrai)

While this tune performs worse than Hermes, it is likely due to the small dataset used. Otherwise, this is a great walkthrough on how to tune these models to improve desired performance on certain tasks.

[### Moving object segmentation (7 minute read)](https://www.robots.ox.ac.uk/~vgg/research/flowsam/?utm_source=tldrai)

Segmenting objects across videos is challenging due to temporal consistency. This work presents the combination of a powerful image segmentation model and optical flow which combined gives compelling performance on this task.

[### Your language model is a Q-function (26 minute read)](https://arxiv.org/abs/2404.12358?utm_source=tldrai)

A fairly technical RL paper that shows the theoretical underpinning of reward models and base models in language.

üë®‚Äçüíª

### Engineering & Resources

[### Using AI automation in process orchestration workflows (Sponsor)](https://page.camunda.com/wp-leveraging-ai-automation?utm_medium=paid_leadgen&utm_content=april_22_ai&utm_source=tldr&utm_campaign=Guide.LeveragingAIAutomation.23Q3.EN)

AI is everywhere now. While current buzz around AI is driven by applications like ChatGPT, AI-powered automation and process orchestration can play a role in everything ‚Äî from carrying out its own tasks, to orchestrating human tasks, to driving continuous improvement. Download this [free ebook by Camunda](https://links.tldr.tech/L7y3Og) to identify where AI fits in your hyperautomation tech stack. [Get the guide here](https://links.tldr.tech/L7y3Og)

[### Training-free Context Extension (GitHub Repo)](https://github.com/dwzhu-pku/longembed?utm_source=tldrai)

Researchers have developed a way to expand the context window of embedding models up to 32,000 tokens without additional training using strategies like position interpolation.

[### FineWeb: 15T high quality web tokens (HuggingFace Hub)](https://huggingface.co/datasets/HuggingFaceFW/fineweb?utm_source=tldrai)

The newest Llama 3 models were trained on 15T tokens. This new dataset contains an extensively deduplicated corpus from common crawl and results in high quality models.

[### Mistral Common (GitHub Repo)](https://github.com/mistralai/mistral-common?utm_source=tldrai)

Mistral has released its tokenizer utilities, chat templates, and more basic tools which it uses internally.

üéÅ

### Miscellaneous

[### Looking For AI Use-Cases (9 minute read)](https://www.ben-evans.com/benedictevans/2024/4/19/looking-for-ai-use-cases?utm_source=tldrai)

This article discusses the transformative potential and current limitations of generative AI like ChatGPT, noting that while it excels in tasks like coding and generating drafts, it struggles with complex tasks that require specific programming. It highlights the need for a vision that matches AI solutions with practical applications, emphasizing that identifying and integrating these into daily workflows remains a significant challenge.

[### Teaching Models To Think Ahead (4 minute read)](https://reasoning-tokens.ghost.io/reasoning-tokens/?utm_source=tldrai)

This article introduces "reasoning tokens" in language models, which generate additional tokens designed to predict future tokens rather than the immediate next one, thereby enhancing the model's ability to think ahead. Experiments demonstrate significant improvements in prediction accuracy, suggesting a potential for more complex reasoning without explicit step-by-step training.

[### A Visual Guide To Vision Transformers (16 minute read)](https://blog.mdturp.ch/posts/2024-04-05-visual_guide_to_vision_transformer.html?utm_source=tldrai)

A visual guide to Vision Transformers (ViTs), a class of deep learning models that have achieved state-of-the-art performance on image classification tasks.

‚ö°Ô∏è

### Quick Links

[### The Cauldron VLM data (HuggingFace Hub)](https://huggingface.co/datasets/HuggingFaceM4/the_cauldron?utm_source=tldrai)

50 vision/language datasets combined into a single format to allow for improved training of models.

[### Llama 3 is not very censored (2 minute read)](https://ollama.com/blog/llama-3-is-not-very-censored?utm_source=tldrai)

The original Llama models had significantly more incorrect refusals. This brief blog shows some examples that previously failed.

[### GPT-4 Can Exploit Real Vulnerabilities By Reading Security Advisories (3 minute read)](https://www.theregister.com/2024/04/17/gpt4_can_exploit_real_vulnerabilities/?utm_source=tldrai)

Researchers have demonstrated that OpenAI's GPT-4 model can autonomously exploit security vulnerabilities detailed in CVE advisories with an 87% success rate, far outperforming other models and tools like vulnerability scanners.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590614