Google invests $2B in Anthropic üí∞, RAG demystified ‚ùì, decomposing LLMs with dictionary learning üìö

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2023-10-30

## Google invests $2B in Anthropic üí∞, RAG demystified ‚ùì, decomposing LLMs with dictionary learning üìö

üöÄ

### Headlines & Launches

[### Amazon Ads Launches AI-Powered Imagery for Advertisers (2 minute read)](https://www.aboutamazon.com/news/innovation-at-amazon/amazon-ads-ai-powered-image-generator?utm_source=tldrai)

Amazon Ads has introduced an AI-powered image generation feature in beta that creates lifestyle and brand-themed images to improve ad performances. The tool, which requires no technical expertise, enables brands to create more engaging ads, reportedly increasing click-through rates by 40%. It will be rolled out progressively to advertisers based on customer feedback.

[### Google Invests $2B Into Anthropic (2 minute read)](https://www.cnbc.com/2023/10/27/google-commits-to-invest-2-billion-in-openai-competitor-anthropic.html?utm_source=tldrai)

Google has committed to a substantial investment in Anthropic, a competitor to OpenAI, earmarking up to $2 billion for the AI startup.

[### First director of the Frontier Models Forum named and big tech adds $10m to safety initiative funding (4 minute read)](https://blog.google/outreach-initiatives/public-policy/google-microsoft-anthropic-open-ai-frontier-model-forum-executive-director/?utm_source=tldrai)

Chris Meserole is the first director of the Frontier Models Forum. Many large tech companies have added funding to the AI safety fund.

üß†

### Research & Innovation

[### Identifying Out-of-Distribution Data (14 minute read)](https://arxiv.org/abs/2309.14888v1?utm_source=tldrai)

ML models can sometimes wrongly recognize unfamiliar data, thinking they've seen it before. A new method, NNGuide, helps models make better decisions, especially when identifying unknown data.

[### Towards Monosemanticity: Decomposing Language Models With Dictionary Learning (60 minute read)](https://transformer-circuits.pub/2023/monosemantic-features/index.html)

Researchers use sparse autoencoders to tackle neural networks' polysemanticity, extracting clearer features for improved model understanding. These features influence outputs and exhibit complex interactions.

[### Emulate training a large model just by training a small one (28 minute read)](https://arxiv.org/abs/2310.12962?utm_source=tldrai)

Emulator Fine Tuning (EFT) comes from the direct preference optimization group and explores what happens if you fine tune a small model and then project that fine tuning onto a large model. This counterintuitive strategy works shockingly well.

üë®‚Äçüíª

### Engineering & Resources

[### AudioFlare (GitHub Repo)](https://github.com/seanoliver/audioflare?utm_source=tldrai)

An all-in-one AI audio playground using Cloudflare AI Workers to transcribe, analyze, summarize, and translate any audio file.

[### Multi-Modal Prompt Injection Image Attacks Against GPT-4V (3 minute read)](https://simonwillison.net/2023/Oct/14/multi-modal-prompt-injection/?utm_source=tldrai)

The new GPT-4V allows for interactive conversations with image inputs but also introduces new vulnerabilities through visual prompt injection attacks, enabling exfiltration of data and execution of hidden instructions encoded in images.

[### A System for Evaluating Large Language Models (GitHub Repo)](https://github.com/baaivision/judgelm?utm_source=tldrai)

This study presents "JudgeLM", a new method to efficiently evaluate Large Language Models in versatile situations. The authors developed a vast dataset and benchmarking system.

üéÅ

### Miscellaneous

[### Is AI alignment on track? Is it progressing... too fast? (8 minute read)](https://guzey.com/ai/alignment-on-track/?utm_source=tldrai)

AI alignment is a complex issue that lacks concrete benchmarks or numbers for measurement. Predictions of AI-induced doom rely on narratives rather than rigorous models. The absence of hard numbers makes it challenging to assess the state of AI alignment.

[### Deep learning in Rust (Book)](https://burn.dev/book/?utm_source=tldrai)

Rust is a popular systems programming language with strong memory safety. Burn is a framework built on these principles for efficient ML. Importantly, it offers compatibility with the Onyx runtime.

[### Thanks to AI, the future of programming may involve YELLING IN ALL CAPS (3 minute read)](https://arstechnica.com/information-technology/2023/10/thanks-to-ai-the-future-of-programming-may-involve-yelling-in-all-caps/?utm_source=tldrai)

OpenAI's prompts reveal many quirks about prompt engineering. For example, the prompts use 'please' a lot and important instructions are often all capitalized. Capitalizing instructions likely works as the models were trained on huge numbers of examples where responses clearly paid more attention to capitalized sentences. This could result in a future where people shout at their computers to get them to work better.

‚ö°Ô∏è

### Quick Links

[### RAG Demystified (GitHub Repo)](https://github.com/pchunduri6/rag-demystified?utm_source=tldrai)

An LLM-powered advanced RAG pipeline.

[### Mistral powered multimodal Llava model (Hugging Face Hub)](https://huggingface.co/SkunkworksAI/BakLLaVA-1?utm_source=tldrai)

The Llava fine tuning paradigm combines powerful language models with vision capabilities. It has been applied with Mistral 7B for improved performance.

[### Spoke (Product)](https://www.spoke.ai/?utm_source=tldrai)

A priority inbox for product teams that reduces information overload, prioritizes work, gives instant context, and augments core workflows using AI.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590584