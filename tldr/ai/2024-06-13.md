Stable Diffusion 3 weights êÑ∑, Shutterstock ImageAI üñºÔ∏è, DeepMind Torax üîã

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2024-06-13

## Stable Diffusion 3 weights êÑ∑, Shutterstock ImageAI üñºÔ∏è, DeepMind Torax üîã

üöÄ

### Headlines & Launches

[### Stable Diffusion 3 Open Weights (4 minute read)](http://stability.ai/news/stable-diffusion-3-medium?utm_source=tldrai)

Stability AI has released SD 3 weights for non-commercial use, with commercial use available on request.

[### Shutterstock ImageAI, powered by Databricks (6 minute read)](https://www.databricks.com/company/newsroom/press-releases/introducing-shutterstock-imageai-powered-databricks-image?utm_source=tldrai)

Databricks has partnered with Shutterstock to build a Shutterstock-branded AI image generation model.

[### OpenAI Annualized Revenue Doubles (1 minute read)](https://seekingalpha.com/news/4115380-openai-annualized-revenue-doubles-to-hit-34b-report?source=content_type%3Areact%7Cfirst_level_url%3Amarket-news%7Csection_asset%3Amain%7Csection%3Atechnology&amp;utm_source=tldrai)

OpenAI has more than doubled its annualized revenue to hit $3.4B.

üß†

### Research & Innovation

[### TextGrad: Automatic Differentiation with Text (18 minute read)](https://arxiv.org/abs/2406.07496?utm_source=tldrai)

This paper explores the idea of treating a language model that can update text as a backpropagation system. The researchers find substantial improvements in benchmark performance, not compute matched, against baseline models.

[### Improve Mathematical Reasoning with Automatic Process Supervision (24 minute read)](https://arxiv.org/abs/2406.06592?utm_source=tldrai)

DeepMind discovered an excellent extension to the human labor-intensive process supervision process. It found that it could automate much of the process with strong base models, leading to substantial mathematical reasoning performance on Gemini Pro tuned models.

[### BERTs are in-context generative learners (21 minute read)](https://arxiv.org/abs/2406.04823?utm_source=tldrai)

In an alternative world, BERT models would have been discovered to be in-context learners instead of their decoder-only GPT counterparts. This paper explores when that is true and finds that, unsurprisingly, BERTs are excellent at information retrieval but struggle with knowledge acquisition - likely due to the bidirectional attention mechanism.

üë®‚Äçüíª

### Engineering & Resources

[### R2R: The ultimate open-source RAG framework (Sponsor)](https://github.com/SciPhi-AI/R2R?utm_source=tldrai)

* üìÅ Multimodal Support: Ingest .txt, .pdf, .json, .png, .mp3, and more.
* üîç Hybrid Search: Combine semantic and keyword search with reciprocal rank fusion for enhanced relevancy.
* üîó Graph RAG: Automatically extract relationships and build knowledge graphs.
* üóÇÔ∏è App Management: Efficiently manage documents and users with rich observability and analytics.
* üåê Client-Server: RESTful API support out of the box.

Visit the [R2R GitHub](https://github.com/SciPhi-AI/R2R) to get started today!

[### Autoregressive Language Models for Image Synthesis (GitHub Repo)](https://github.com/FoundationVision/LlamaGen?utm_source=tldrai)

Llama Gen is an autoregressive model that scales better than diffusion alternatives for image generation. Its researchers trained a class-conditioned model on ImageNet and achieved a new state-of-the-art for FID.

[### DeepMind Torax (GitHub Repo)](https://github.com/google-deepmind/torax?utm_source=tldrai)

Google's DeepMind has open-sourced its differentiable fusion tokamak simulator written in Python-Jax. The simulator has strong auto-diff capabilities and covers a number of extremely powerful PDEs.

[### Speeding Up Diffusion Models with AsyncDiff (3 minute read)](https://czg1225.github.io/asyncdiff_page/?utm_source=tldrai)

AsyncDiff is a new acceleration scheme that enables parallel computation in diffusion models. It significantly reduces latency without compromising quality by dividing the noise prediction model into multiple components and running them on separate devices.

üéÅ

### Miscellaneous

[### Efficient LLMs with Speculative Decoding (16 minute read)](https://arxiv.org/abs/2406.07368v1?utm_source=tldrai)

Researchers have tackled the efficiency issues in autoregressive large language models by exploring linear attention methods combined with speculative decoding. This study introduces an augmentation technique for linear attention, making it compatible with speculative decoding and improving both training and performance.

[### Maintaining Large-Scale AI Capacity At Meta (6 minute read)](https://engineering.fb.com/2024/06/12/production-engineering/maintaining-large-scale-ai-capacity-meta/?utm_source=tldrai)

Meta is upgrading its global data centers to support AI demands. It is planning to scale to 600,000 GPUs for AI training jobs. This involves innovative maintenance strategies and tools like OpsPlanner to ensure minimal disruptions and consistent performance while enabling rapid infrastructure scaling.

‚ö°Ô∏è

### Quick Links

[### Here's how you can mass delete your old posts, tweets, and comments (Sponsor)](https://redact.dev/?utm_medium=newsletter&amp;utm_source=tldr-ai&amp;utm_campaign=20240613AIQuickLinks)

Social networks make it hard to delete your history. Redact makes it easy. Automatically remove your content from Twitter, Reddit, Facebook, Discord, and 35+ other services. [Start for free](https://redact.dev/?utm_medium=newsletter&utm_source=tldr-ai&utm_campaign=20240613AIQuickLinks)

[### Powerinfer-2 (12 minute read)](https://powerinfer.ai/v2/?utm_source=tldrai)

Fast inference on the phone for the special Mistral 47B MoE model.

[### AXLearn (GitHub Repo)](https://github.com/apple/axlearn?utm_source=tldrai)

A library built on top of JAX and XLA that supports the development of large-scale deep learning models.

[### Perplexity was planning revenue-sharing deals with publishers when it came under media fire (4 minute read)](https://www.semafor.com/article/06/12/2024/perplexity-was-planning-revenue-sharing-deals-with-publishers?utm_source=tldrai)

Perplexity is planning revenue-sharing deals with high-quality publishers for a recurring income stream.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590624