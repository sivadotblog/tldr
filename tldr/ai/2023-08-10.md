82% of Americans want to slow AI development üèÉ, Anthropic releases Claude Instant ‚è©, understanding grokking üß†

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2023-08-10

## 82% of Americans want to slow AI development üèÉ, Anthropic releases Claude Instant ‚è©, understanding grokking üß†

üöÄ

### Headlines & Launches

[### 82% of Americans think we should slow down AI development (7 minute read)](https://www.axios.com/2023/08/09/ai-voters-trust-government-regulation?utm_source=tldrai)

In a new Axios survey of 1001 people across one week in July, participants expressed their opinions on a variety of topics around AI safety and capabilities development. 52% think there needs to be government regulation and a vast majority more believe large tech giants can't be trusted to self regulate.

[### Inworld AI Becomes the Best-Funded Startup in AI x Gaming (8 minute read)](https://inworld.ai/blog/inworld-valued-at-500-million?utm_source=tldrai)

Inworld AI announced a new $50M+ round led by Lightspeed Venture Partners, bringing the total valuation of the company to over $500M. This will allow Inworld to accelerate R&D efforts, hire top talent, build a more robust Character Engine, expand infrastructure, and open source parts of its platform.

[### Anthropic Launches Improved Version Of Its Entry-Level LLM (3 minute read)](https://techcrunch.com/2023/08/09/anthropic-launches-improved-version-of-its-entry-level-llm/?utm_source=tldrai)

Anthropic has released Claude Instant, an updated version of its faster, cheaper, text-generating model. Claude Instant generates longer, more structured responses, follows formatting instructions better, and shows improvements in quote extraction, multilingual capabilities, and question answering. It is available through an API.

üß†

### Research & Innovation

[### Understanding Grokking (21 minute read)](https://pair.withgoogle.com/explorables/grokking/?utm_source=tldrai)

The PAIR group at Google has released a lovely explainer that goes deep into the topic of Grokking. Grokking is the dynamic process a model goes through during training that may point to a shift from memorizing to understanding. It isn't well understood in general, but this is a lovely introduction that covers much of the groundwork for this strange phenomenon.

[### Photorealistic synthetic data in unreal engine (17 minute read)](https://arxiv.org/abs/2308.03977?utm_source=tldrai)

Don't have millions of photorealistic images to train your algorithm? Maybe you can generate them using PUG from Meta AI. It uses the powerful unreal game engine in a controllable way to generate synthetic image data for downstream training.

[### Simple synthetic data reduces sycophancy (23 minute read)](https://arxiv.org/abs/2308.03958?utm_source=tldrai)

Sycophancy is when a model repeats and adopts a user's opinion. This happens more in larger models and instruction-tuned models. It can also occur in tasks when the opinion is irrelevant, leading to bubble-like behavior. Simple synthetic data fine-tuning can prevent this without harming overall performance.

üë®‚Äçüíª

### Engineering & Resources

[### Get 80% end-to-end test coverage in 4 months (Sponsor)](https://www.qawolf.com/?utm_campaign=Get80PercentEndToEnd08102023&amp;utm_source=tldrai&amp;utm_medium=newsletter)

There‚Äôs a shortcut to reaching high automated test coverage, without spending years on scaling in-house teams. The answer? It's not AI. It's [QA Wolf.](https://www.qawolf.com/?utm_campaign=Get80PercentEndToEnd08102023&utm_source=tldrai&utm_medium=newsletter)QA Wolf gets you to [80% automated end-to-end test coverage in 4 months](https://www.qawolf.com/?utm_campaign=Get80PercentEndToEnd08102023&utm_source=tldrai&utm_medium=newsletter). Plus, they do all the test maintenance, provide unlimited parallel test runs on their infrastructure, and send human-verified bug reports directly to your issue tracker.

Skeptical? [Schedule a demo to learn more.](https://www.qawolf.com/?utm_campaign=Get80PercentEndToEnd08102023&utm_source=tldrai&utm_medium=newsletter)PS: QA Wolf has a 4.8/5 ‚≠ê rating on G2 and they have multiple case studies of customers saving $480k+ on QA engineering.

[### Integrate Private Data into LLMs while Preserving Privacy (GitHub Repo)](https://github.com/rcgai/simplyretrieve?utm_source=tldrai)

Generative AI systems have grown with the help of Large Language Models. The SimplyRetrieve open-source tool offers a user-friendly way to integrate private data into these systems without extra tuning using the Retrieval-Centric Generation approach. It promises enhanced AI performance while ensuring privacy.

[### A New Method for Improving Student Networks in Computer Vision (GitHub Repo)](https://github.com/amirmansurian/aicsd?utm_source=tldrai)

Deep neural networks have excelled in computer vision, but faster inference times are needed. This paper introduces the Inter-Class Similarity Distillation method and an Adaptive Loss Weighting strategy for better knowledge transfer from a teacher network to a student one.

[### Magentic (GitHub Repo)](https://github.com/jackmpcollins/magentic?utm_source=tldrai)

Magentic makes it easy to integrate Large Language Models (LLMs) into your Python code. Treat prompt templates as functions, using type annotations to specify structured output. Then, seamlessly mix LLM queries and function calling with regular Python code to create complex LLM-powered functionality.

üéÅ

### Miscellaneous

[### White House Announces ‚ÄòAI Cyber Challenge‚Äô (3 minute read)](https://www.engadget.com/the-white-houses-ai-cyber-challenge-aims-to-crowdsource-national-security-solutions-170003434.html?utm_source=tldrai)

The Biden Administration revealed its plans to better defend the nation‚Äôs critical digital infrastructure at the Black Hat USA Conference in Las Vegas on Wednesday: it's launching a DARPA-led challenge competition to build AI systems capable of proactively identifying and fixing software vulnerabilities.

[### Llama From Scratch (20 minute read)](https://blog.briankitano.com/llama-from-scratch/?utm_source=tldrai)

A step-by-step guide for using the Llama paper to train TinyShakespeare.

[### Google Is Working On ‚ÄòBrain2Music‚Äô (2 minute read)](https://indianexpress.com/article/technology/artificial-intelligence/googles-brain2music-ai-can-listen-to-your-brain-signals-to-reproduce-music-you-listened-to-8882357/?utm_source=tldrai)

Google is working on a new AI called ‚ÄòBrain2Music‚Äô that uses brain imaging data to generate music. Researchers say the AI model can generate music that closely resembles parts of songs a person was listening to when their brain was scanned.

‚ö°Ô∏è

### Quick Links

[### Parea AI - the developer toolkit for debugging and monitoring LLM apps (Product)](https://www.parea.ai/?utm_source=tldrai)

Experiment with prompts & model configurations in a versioned manner. Evaluate prompts with custom-defined Python evaluation metrics on a large scale. Monitor LLM applications via API and view analytics on a dashboard.

[### Fastest way to tune Llama (Colab Link)](https://colab.research.google.com/drive/1Zmaceu65d7w4Tcd-cfnZRb6k_Tcv2b8g?utm_source=tldrai)

Upload your JSONL data to your drive, link it, and run this notebook with QLoRA and SFT training to get a custom-tuned Llama2 model. This seems to be the most minimal example I have found for tuning and works well. Most importantly, the model uses a (prompt, response) format.

[### api2ai (GitHub Repo)](https://github.com/mquan/api2ai?utm_source=tldrai)

Create an API assistant from any OpenAPI spec.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590569