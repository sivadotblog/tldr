Mistral‚Äôs new model & funding üí∞, Google AlphaCode 2 üßë‚Äçüíª, StableLM Zephyr 3B ü§ñ

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2023-12-11

## Mistral‚Äôs new model & funding üí∞, Google AlphaCode 2 üßë‚Äçüíª, StableLM Zephyr 3B ü§ñ

### 

[### Solving the enterprise data bottleneck with synthetic data (Sponsor)](https://info.gretel.ai/solution-brief?utm_source=tldr-ai&amp;utm_campaign=20231208)

AI/ML, research, and development teams are blocked by a solitary point of failure‚Äîlack of [fast access to high-quality data](https://info.gretel.ai/solution-brief?utm_source=tldr-ai&utm_campaign=20231208). When data is unavailable, of low quality, or contains sensitive information, developers can‚Äôt use it to build. The result: data doesn‚Äôt reach the teams who need it most ‚Äî and innovation suffers.

[Gretel](https://info.gretel.ai/solution-brief?utm_source=tldr-ai&utm_campaign=20231208) provides the end-to-end tools for generating, evaluating, and operationalizing synthetic data for diverse enterprise use cases. [Download the solution brief](https://info.gretel.ai/solution-brief?utm_source=tldr-ai&utm_campaign=20231208) to learn how Gretel and synthetic data can [solve the data bottleneck for your dev team](https://info.gretel.ai/solution-brief?utm_source=tldr-ai&utm_campaign=20231208).

üöÄ

### Headlines & Launches

[### Google Unveils AlphaCode 2, Powered By Gemini (2 minute read)](https://techcrunch.com/2023/12/06/deepmind-unveils-alphacode-2-powered-by-gemini/?utm_source=tldrai)

Google's DeepMind has released AlphaCode 2, an improved code-generating AI model that outperforms 85% of human competitors in programming contests, showcasing advanced capabilities in solving complex mathematical and theoretical computer science problems.

[### Stability AI Launches StableLM Zephyr 3B (2 minute read)](https://stability.ai/news/stablelm-zephyr-3b-stability-llm?utm_source=tldrai)

StableLM Zephyr 3B, a new 3 billion parameter chat model, is being released as an extension of the StableLM 3B-4e1t model, drawing inspiration from the Zephyr 7B model. It is designed for efficient text generation, particularly in instruction following and Q&A contexts, and has been fine-tuned on multiple datasets using the Direct Preference Optimization algorithm.

[### Mistral's new model and new funding (7 minute read)](https://www.ft.com/content/ea29ddf8-91cb-45e8-86a0-f501ab7ad9bb?utm_source=tldrai)

The 8-month-old AI group is set to raise $400m+ in a new round. It also released an 8x7B Mixture of Experts model which is currently being evaluated by the community.

üß†

### Research & Innovation

[### Video Editing with Pre-trained Text-to-Image Diffusion Models (3 minute read)](https://rave-video.github.io/?utm_source=tldrai)

RAVE is a video editing method that uses existing text-to-image diffusion models to enhance videos. This approach allows for high-quality video edits while maintaining the original movement and structure.

[### Better, cheaper, faster alignment with KTO (12 minute read)](https://contextual.ai/better-cheaper-faster-llm-alignment-with-kto/?utm_source=tldrai)

Most alignment frameworks require ranked preference data (A is preferred to B). This is usually expensive and rare. This new framework only requires an independent yes or no rating per data point.

[### StripedHyena 7B model (15 minute read)](https://www.together.ai/blog/stripedhyena-7b?utm_source=tldrai)

Transformer models have dominated the AI landscape recently. They are powerful sequence learners but have some drawbacks. This new work, which builds on state space models, shows that new architectures can bring great benefits like increased context length.

üë®‚Äçüíª

### Engineering & Resources

[### Understanding 100x speed up in LLM inference (38 minute read)](https://yaofu.notion.site/Towards-100x-Speedup-Full-Stack-Transformer-Inference-Optimization-43124c3688e14cffaf2f1d6cbdf26c6c?utm_source=tldrai)

With open models becoming useful for many enterprise tasks, people are starting to explore deployment optimizations. However, the landscape is complex and scattered. This post is a nice deep dive into many of the standard techniques used to speed up language model serving.

[### Pearl (GitHub Repo)](https://github.com/facebookresearch/Pearl?utm_source=tldrai)

A Production-ready Reinforcement Learning AI Agent Library brought by the Applied Reinforcement Learning team at Meta.

[### Multi-Conditional Diffusion Model for Scene Synthesis (GitHub Repo)](https://github.com/andvg3/LSDM?utm_source=tldrai)

Scene creation, guided by factors like human movement or room design, gets a fresh angle by integrating textual prompts. This repo introduces a novel approach, a multi-conditional diffusion model, that efficiently merges text, movement, and existing objects.

üéÅ

### Miscellaneous

[### Excuse Me, But The Industries AI Is Disrupting Are Not Lucrative (12 minute read)](https://www.theintrinsicperspective.com/p/excuse-me-but-the-industries-ai-is?utm_source=tldrai)

Google's Gemini AI model, despite an impressive demo video, saw only a minimal stock increase for Google, reflecting skepticism about its real-time capabilities as the demo used pre-recorded footage and edited responses. This skepticism mirrors broader concerns in the AI industry, where companies create high expectations but face challenges in translating AI capabilities into substantial economic gains, with current AI models excelling in areas that don't necessarily yield high financial returns.

[### Running LLMs locally with Ollama (4 minute read)](https://erichartford.com/running-dolphin-locally-with-ollama?utm_source=tldrai)

Ollama is like a package manager around llama cpp models. It has quality-of-life usability features and makes it easy to run models, even on a CPU. This example shows how to run two great models, Dolphin and Samantha, which are excellent unfiltered models useful for conversational tasks.

[### LLM Visualization (Website)](https://bbycroft.net/llm?utm_source=tldrai)

This site looks at how the nano-gpt model, which has 85,000 parameters, sorts a sequence of six letters into alphabetical order.

‚ö°Ô∏è

### Quick Links

[### How to Build an AI Capable of Thought (Sponsor)](https://aithought.com/?utm_source=tldr-ai&amp;utm_campaign=20231211)

This article presents a framework to simulate human-like thought processes in a computer, as a path to AGI. Contains numerous unique illustrations by Jared Reser Ph.D. [Read the paper (free, ungated)](https://aithought.com/?utm_source=tldr-ai&utm_campaign=20231211)

[### Giskard (GitHub Repo)](https://github.com/Giskard-AI/giskard?utm_source=tldrai)

The testing framework for ML models from tabular to LLMs.

[### Liquid AI, a new MIT spinoff, wants to build an entirely new type of AI (4 minute read)](https://techcrunch.com/2023/12/06/liquid-ai-a-new-mit-spinoff-wants-to-build-an-entirely-new-type-of-ai?utm_source=tldrai)

Liquid neural networks are much smaller than traditional AI models and require far less compute power to run.

[### FTC Looking Into Microsoft‚Äôs Investment In OpenAI (2 minute read)](https://finance.yahoo.com/video/ftc-looking-microsofts-investment-openai-222919020.html?utm_source=tldrai)

The Federal Trade Commission (FTC) is inspecting Microsoft's relationship with and investment in OpenAI.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590591