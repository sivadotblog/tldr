OpenAI‚Äôs Deep Research üß™, Anthropic Constitutional Classifiers üìú, RLHF Book üìö

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2025-02-04

## OpenAI‚Äôs Deep Research üß™, Anthropic Constitutional Classifiers üìú, RLHF Book üìö

### 

[### Start Here: 5 Tips to Fight AI Security Risk (Sponsor)](https://www.wiz.io/lp/getting-started-with-ai-security-ai-risks-how-to-prevent-them-and-ai-for-defender?utm_source=tldr-ai&amp;utm_medium=paid-email&amp;utm_campaign=FY25Q3_INB_FORM_Getting-Started-with-AI-Security-AI-Risks-How-to-Prevent-Them&amp;sfcid=701Py00000DP3ZaIAL&amp;utm_term=FY26Q1-tldr-ai-nl&amp;utm_content=AISecurityeBook)

Don't let AI risks catch you off guard.

Most AI security risks fall into 4 primary categories - Adversarial attacks, model inversion attacks, data poisoning, and model theft.

Given these risks in AI systems, what's the best way to secure them?

Wiz recently put together an eBook, [Getting Started with AI Security](https://www.wiz.io/lp/getting-started-with-ai-security-ai-risks-how-to-prevent-them-and-ai-for-defender?utm_source=tldr-ai&utm_medium=paid-email&utm_campaign=FY25Q3_INB_FORM_Getting-Started-with-AI-Security-AI-Risks-How-to-Prevent-Them&sfcid=701Py00000DP3ZaIAL&utm_term=FY26Q1-tldr-ai-nl&utm_content=AISecurityeBook), to answer that exact question across the following areas:

* AI risks and best practices for mitigation
* Safeguarding your AI development pipeline
* Using AI to power security

Discover the 5 best strategies to secure them in this essential guide.

[Get the eBook](https://www.wiz.io/lp/getting-started-with-ai-security-ai-risks-how-to-prevent-them-and-ai-for-defender?utm_source=tldr-ai&utm_medium=paid-email&utm_campaign=FY25Q3_INB_FORM_Getting-Started-with-AI-Security-AI-Risks-How-to-Prevent-Them&sfcid=701Py00000DP3ZaIAL&utm_term=FY26Q1-tldr-ai-nl&utm_content=AISecurityeBook)

üöÄ

### Headlines & Launches

[### Why everyone is freaking out about DeepSeek (13 minute read)](https://www.theverge.com/ai-artificial-intelligence/598846/deepseek-big-tech-ai-industry-nvidia-impac?utm_source=tldrai)

DeepSeek's AI models, which are significantly cheaper to train compared to other leading models, have disrupted the AI market, potentially challenging Nvidia and other tech giants by showcasing efficient use of resources. This has shaken investor confidence in the AI sector, which traditionally believed that more spending equated to better performance. DeepSeek's success suggests that innovation, rather than just financial investment, could redefine the competitive landscape.

[### OpenAI's Deep Research (4 minute read)](https://openai.com/index/introducing-deep-research/?utm_source=tldrai)

OpenAI has introduced "Deep Research," an autonomous research agent within ChatGPT capable of performing multi-step research by synthesizing vast online sources. It is powered by an optimized version of the upcoming OpenAI o3 model.

[### Constitutional Classifiers: Defending against universal jailbreaks (8 minute read)](https://www.anthropic.com/research/constitutional-classifiers?utm_source=tldrai)

A new paper from the Anthropic Safeguards Research Team describes a method that defends AI models against universal jailbreaks. A prototype version of the method was robust to thousands of hours of human red teaming for universal jailbreaks, albeit with high over-refusal rates and compute overhead. An updated version achieved similar robustness on synthetic evaluations and did so with a 0.38% increase in refusal rates and moderate additional compute costs.

üß†

### Research & Innovation

[### DeepMind's Decoding-Based Regression in Language Models (22 minute read)](https://arxiv.org/abs/2501.19383v1?utm_source=tldrai)

DeepMind researchers analyzed how language models can perform regression tasks by decoding numeric predictions as text and found them as effective as traditional regression models while also enabling flexible density estimation.

[### Diffusion Autoencoders are Scalable Image Tokenizers (12 minute read)](https://yinboc.github.io/dito/?utm_source=tldrai)

The modern workhorse of multimodal understanding and generation is learned Tokenizers. These models are typically autoencoder style with a learned discrete codebook. They tend to work well but are very hard to train and require careful tuning of many auxiliary losses. This work shows that with a single diffusion loss, image tokenization is stable, scalable, and higher quality than many traditional methods.

[### s1: Simple test-time scaling (45 minute read)](https://arxiv.org/abs/2501.19393?utm_source=tldrai)

A great and thorough paper that explores how to encourage models to use more thinking tokens. One of the main findings is that with an extremely high-quality curated dataset of 1k examples and by appending ‚Äúwait‚Äù to the end of a thinking sequence, you can encourage models to think longer, which leads to substantially improved performance on math and reasoning tasks.

üë®‚Äçüíª

### Engineering & Resources

[### Gaussian Splatting for 3D Rendering (GitHub Repo)](https://github.com/kbyrski/raysplatting?utm_source=tldrai)

RaySplats enhances 3D Gaussian Splatting by integrating ray tracing, improving the handling of light and shadows in 3D object rendering while maintaining fast training and rendering speeds.

[### Kron Optimizer (GitHub Repo)](https://github.com/evanatyourservice/kron_torch?utm_source=tldrai)

Kron is a new optimizer that is making the rounds as a strong alternative to second-order methods. It dramatically outperforms Adam on a number of baselines. This code is a drop-in optimizer for PyTorch.

[### Everything you need to build state-of-the-art foundation models (GitHub Repo)](https://github.com/oumi-ai/oumi?utm_source=tldrai)

Oumi is a fully open-source platform that streamlines the entire lifecycle of foundation models, from data preparation and training to evaluation and deployment. Whether you're developing on a laptop, launching large-scale experiments on a cluster, or deploying models in production, Oumi provides the tools and workflows you need.

üéÅ

### Miscellaneous

[### RLHF Book - Policy Gradients (45 minute read)](https://rlhfbook.com/c/11-policy-gradients.html?utm_source=tldrai)

Great chapter on many policy gradient methods like PPO and GRPO, which can be used for tuning generative auto-regressive models.

[### AI haters build tarpits to trap and trick AI scrapers that ignore robots.txt (12 minute read)](https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/?utm_source=tldrai)

Nepenthes is a tarpit malware designed to trap and poison AI web crawlers that ignore robots.txt rules. The release of Nepenthes has inspired other tools like Iocaine that aim to hinder AI data collection and impact the industry financially.

[### OpenAI's new anti-jobs program (7 minute read)](https://www.vox.com/future-perfect/396548/openai-trump-artificial-intelligence-elon-musk-sam-altman-china?utm_source=tldrai)

OpenAI plans a $500 billion investment in "Stargate," a project aimed at creating AI infrastructure, while economists debate the job-creation claim as automation may perform most computer-based tasks. DeepSeek has made significant advances with self-improving reinforcement learning, potentially leading to rapid AI capability improvements. This underscores China's quick progress in AI, highlighting geopolitical stakes in the technology race.

‚ö°Ô∏è

### Quick Links

[### Chinese AI firm DeepSeek has 50,000 NVIDIA H100 AI GPUs says CEO, even with US restrictions (3 minute read)](https://www.tweaktown.com/news/102798/chinese-ai-firm-deepseek-has-50-000-nvidia-h100-gpus-says-ceo-even-with-us-restrictions/index.html?utm_source=tldrai)

DeepSeek, a Chinese AI lab, leveraged tens of thousands of NVIDIA H100 GPUs to develop its R1 model, which competes with top AI models like OpenAI's o1 and Meta's Llama.

[### Jack Dorsey's Block has an AI agent too (2 minute read)](https://www.engadget.com/ai/jack-dorseys-block-has-an-ai-agent-too-212706083.html?utm_source=tldrai)

Jack Dorsey's Block has developed an open-source AI agent named "codename goose" for automating engineering tasks using popular LLMs.

[### David Sacks claims there's 'substantial evidence' that DeepSeek used OpenAI's models to train its own (1 minute read)](https://techcrunch.com/2025/01/28/david-sacks-claims-theres-substantial-evidence-that-deepseek-used-openais-models-to-train-its-own/?utm_source=tldrai)

David Sacks accused Chinese AI firm DeepSeek of using OpenAI's models to train its own, likening the act to theft.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590664