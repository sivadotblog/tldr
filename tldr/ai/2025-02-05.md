Google CEO on DeepSeek ü§ñ, Hugging Face replicates OpenAI Deep Research üîç, In-Context Reinforcement Learning üìö

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2025-02-05

## Google CEO on DeepSeek ü§ñ, Hugging Face replicates OpenAI Deep Research üîç, In-Context Reinforcement Learning üìö

üöÄ

### Headlines & Launches

[### Hugging Face Replicating OpenAI's Deep Research (9 minute read)](https://huggingface.co/blog/open-deep-research?utm_source=tldrai)

Hugging Face attempted to replicate OpenAI's Deep Research, an agentic web-search framework that significantly improved performance on the GAIA benchmark, by running a 24-hour-long experiment aimed at open-sourcing an equivalent system.

[### Google CEO on DeepSeek vs. Gemini (4 minute read)](https://www.crn.com/news/ai/2025/google-q4-2024-earnings-ceo-pichai-says-deepseek-models-less-efficient-than-gemini-s?utm_source=tldrai)

Sundar Pichai has downplayed the efficiency of DeepSeek's AI models, arguing that Google's Gemini models, particularly Gemini 2.0 Flash, outperform them despite DeepSeek's disruptive impact on the AI market.

[### US Copyright Office rules out copyright for AI created content without human input (3 minute read)](https://www.techspot.com/news/106562-us-copyright-office-rules-out-copyright-ai-created.html?utm_source=tldrai)

The US Copyright Office states that AI-generated works without human intervention cannot be copyrighted. AI tools assisting with creativity, like de-aging actors, won't limit copyright protection, but purely generative AI outputs require further analysis.

üß†

### Research & Innovation

[### Harmonic Loss Trains Interpretable AI Models (18 minute read)](https://arxiv.org/abs/2502.01628?utm_source=tldrai)

Harmonic loss is an alternative to cross-entropy loss for training neural networks that offers better interpretability and faster convergence through scale invariance and finite convergence points. Experiments across algorithmic, vision, and language datasets, demonstrate that models trained with harmonic loss show superior performance in interpretability, data efficiency, and reduced grokking compared to standard models. Harmonic loss could be particularly valuable for applications with limited data or where interpretability is crucial.

[### Convex Optimization Theory and Learning-Rate Scheduling for Large Model Training (28 minute read)](https://arxiv.org/abs/2501.18965?utm_source=tldrai)

Learning-rate schedules for large models closely match theoretical bounds from non-smooth convex optimization. These authors provide a bound for constant schedules with linear cooldown, showing cooldown's practical benefits through the absence of logarithmic terms in the bound. Their findings enabled practical improvements in training Llama-type models through optimal learning-rate extension and cross-schedule transfer.

[### In-Context Reinforcement Learning (14 minute read)](https://arxiv.org/abs/2501.19400v1?utm_source=tldrai)

This study explores scaling In-Context Reinforcement Learning (ICRL) to broader domains using Algorithm Distillation and shows that ICRL can be a viable alternative to expert distillation for generalist decision-making systems.

üë®‚Äçüíª

### Engineering & Resources

[### Forrester Predicts 75% of DIY AI Fails in 2025 (Sponsor)](https://more.suse.com/Forrester_Artificial_Intelligence_Predictions.html?utm_source=&amp;utm_medium=&amp;utm_campaign=2_0007061_Forrester_Artificial_Intelligence_Predictions_for_2025_us_2025153_en&amp;utm_term=TLDR)

The explosive adoption of AI in 2024 has left many businesses with spiraling costs and questionable ROI. The way forward? Ditching cobbled-together deployments for [enterprise AI platforms](https://more.suse.com/Forrester_Artificial_Intelligence_Predictions.html?utm_source=&utm_medium=&utm_campaign=2_0007061_Forrester_Artificial_Intelligence_Predictions_for_2025_us_2025153_en&utm_term=TLDR) ‚Äî which provides choice and control over AI solutions with complete sovereignty from an integrated, extensible platform. [Read the Forrester report](https://more.suse.com/Forrester_Artificial_Intelligence_Predictions.html?utm_source=&utm_medium=&utm_campaign=2_0007061_Forrester_Artificial_Intelligence_Predictions_for_2025_us_2025153_en&utm_term=TLDR)

[### GOT OCR 2.0 Weights (Hugging Face Hub)](https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf?utm_source=tldrai)

One of the best OCR models is now available and integrated with the Hugging Face ecosystem. It works well on documents and sheet music.

[### Open-Vocabulary Detection with LLMs (GitHub Repo)](https://github.com/isee-laboratory/llmdet?utm_source=tldrai)

LLMDet is an open-vocabulary detector that leverages a large language model for enhanced caption generation and grounding that significantly boosts performance compared to existing detectors.

[### Efficient Chain-of-Thought Reasoning (16 minute read)](https://arxiv.org/abs/2501.19201v1?utm_source=tldrai)

Heima introduces a framework for more efficient multimodal reasoning by compressing Chain-of-Thought processes into a single hidden token.

üéÅ

### Miscellaneous

[### How To Scale Your Model (18 minute read)](https://jax-ml.github.io/scaling-book/?utm_source=tldrai)

Amazing post from the DeepMind team about the mental process they use to scale their model. They break it down into mathematical equations, which allows them to reason about the costs of each operation and ensure correctness.

[### Who is Liang Wenfeng? DeepSeek founder comes from AI investing (1 minute read)](https://techcrunch.com/2025/01/28/who-is-liang-wenfeng-deepseek-founder-comes-from-ai-investing/?utm_source=tldrai)

DeepSeek's R1 reasoning model uses less computing power than its U.S. counterparts and is open source. The DeepSeek app topped App Store charts over ChatGPT. Founder Liang Wenfeng previously started AI firms and his hedge fund High-Flyer manages $8 billion, backing DeepSeek. Liang sets himself apart by offering the product for free and open source.

[### AI and the Future of National Security (8 minute read)](https://blog.google/technology/safety-security/ai-and-the-future-of-national-security/?utm_source=tldrai)

Google highlights the strategic importance of AI and quantum computing for national security, emphasizing the need for private-sector leadership, government procurement reforms, and public-private collaboration to strengthen cybersecurity.

‚ö°Ô∏è

### Quick Links

[### Meta AI can now use your Facebook and Instagram data to personalize its responses (2 minute read)](https://techcrunch.com/2025/01/27/meta-ai-can-now-use-your-facebook-and-instagram-data-to-personalize-its-responses/?utm_source=tldrai)

Meta is enhancing its AI chatbot with memory capabilities that will allow it to remember user details in conversations on Facebook, Messenger, and WhatsApp in the U.S.

[### Google's 2024 Responsible AI Report (6 minute read)](https://blog.google/technology/ai/responsible-ai-2024-report-ongoing-work/?utm_source=tldrai)

Google has released its 6th annual Responsible AI Progress Report, which details governance structures, safety evaluations, and risk mitigation techniques for AI product development.

[### Hugging Face researchers are trying to build a more open version of DeepSeek's AI 'reasoning' model (5 minute read)](https://techcrunch.com/2025/01/28/hugging-face-researchers-are-trying-to-build-a-more-open-version-of-deepseeks-ai-reasoning-model/?utm_source=tldrai)

Hugging Face is working to replicate DeepSeek's R1 model with an open-source initiative called Open-R1, addressing concerns over the lack of transparency in DeepSeek's release.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590664