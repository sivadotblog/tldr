xAI raises $6B üí∞, OpenAI o3 safety policy ü¶∫, Claude for threat analysis üîç

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2024-12-26

## xAI raises $6B üí∞, OpenAI o3 safety policy ü¶∫, Claude for threat analysis üîç

üöÄ

### Headlines & Launches

[### Elon Musk's xAI lands $6B in new cash to fuel AI ambitions (6 minute read)](https://techcrunch.com/2024/12/23/elon-musks-xai-lands-billions-in-new-cash-to-fuel-ai-ambitions/?utm_source=tldrai)

xAI raised $6 billion in Series C, doubling its valuation to $45 billion. The company aims to accelerate infrastructure and product development, using models like Grok to enhance capabilities on X. xAI continues to expand amidst legal challenges with OpenAI, leveraging data from Musk's ventures and planning further fundraising next year.

[### Sriram Krishnan named Trump's senior policy advisor for AI (2 minute read)](https://techcrunch.com/2024/12/22/sriram-krishnan-named-trumps-senior-policy-advisor-for-ai/?utm_source=tldrai)

Sriram Krishnan, former a16z general partner, will serve as senior policy advisor for AI at the White House Office of Science and Technology Policy under Trump. He will coordinate AI policy across the government and work closely with David Sacks. Krishnan's background includes leadership roles at Microsoft, Twitter, and Facebook, and he has a strong relationship with Elon Musk.

[### OpenAI trained o1 and o3 to 'think' about its safety policy (7 minute read)](https://techcrunch.com/2024/12/22/openai-trained-o1-and-o3-to-think-about-its-safety-policy/?utm_source=tldrai)

OpenAI enhanced reasoning and safety features in its new AI model family, o3, using a novel "deliberative alignment" process. This method improves the alignment of AI model responses with OpenAI's safety values by referencing those values during inference without human-written data. Deliberative alignment, combined with advanced techniques like synthetic data and reinforcement learning, makes o3 OpenAI's safest model yet. It is set to release in 2025.

üß†

### Research & Innovation

[### Understanding Medical Decision-Making (18 minute read)](https://arxiv.org/abs/2408.12980v1?utm_source=tldrai)

MedDec is a dataset that helps improve the extraction of medical decisions from clinical notes. It covers eleven different diseases. The dataset is annotated with ten types of medical decisions.

[### LLMs Will Always Hallucinate, and We Need to Live With This (30 minute read)](https://arxiv.org/abs/2409.05746?utm_source=tldrai)

As large language models become more ubiquitous across domains, it becomes important to examine their inherent limitations critically. Hallucinations in language models are not just occasional errors, but an inevitable feature of these systems.

[### High-Speed Robotics Simulator (33 minute read)](https://arxiv.org/abs/2410.00425v1?utm_source=tldrai)

ManiSkill3 is an advanced, open-source robotics simulator designed for scalable learning and manipulation tasks.

üë®‚Äçüíª

### Engineering & Resources

[### A Toolkit for Speech Emotion Recognition (GitHub Repo)](https://github.com/emo-box/emobox?utm_source=tldrai)

EmoBox is a comprehensive toolkit designed to address common issues in Speech Emotion Recognition (SER). It provides a multilingual, multi-corpus benchmark for both intra-corpus and cross-corpus settings, enabling easier comparison and reproduction of SER models.

[### Cancer Detection (GitHub Repo)](https://github.com/vvjia/sam-swin?utm_source=tldrai)

SAM-Swin is a model for detecting laryngo-pharyngeal cancer (LPC) that uses advanced features from the Segment Anything Model 2 (SAM2).

[### How to get real GPU utilization metrics (GitHub Repo)](https://github.com/stas00/ml-engineering/blob/master/compute/accelerator/nvidia/debug.md#how-to-get-the-real-gpu-utilization-metrics?utm_source=tldrai)

Nvidia-smi shows a measure of GPU utilization but it is the amount of time where at least one kernel is running, not a full measure of GPU usage. This work by Stas shows how you can get actual FLOP usage.

üéÅ

### Miscellaneous

[### So many tokens, so little time: Introducing a faster, more flexible byte-pair tokenizer (12 minute read)](https://github.blog/ai-and-ml/llms/so-many-tokens-so-little-time-introducing-a-faster-more-flexible-byte-pair-tokenizer/?utm_source=tldrai)

GitHub has released a new open-source byte-pair tokenizer that improves speed and flexibility for large language models like Copilot, scaling better with linear complexity. This tokenizer addresses limitations of existing BPE algorithms by efficiently supporting dynamic token counts for real-time text operations. It outperforms popular libraries like tiktoken and Hugging Face in benchmarks, significantly boosting performance for various applications.

[### How Claude uses AI to identify new threats (13 minute read)](https://www.platformer.news/how-claude-uses-ai-to-identify-new-threats/?utm_source=tldrai)

Anthropic's Clio tool identified a coordinated effort to generate SEO spam using its chatbot, Claude, leading to the termination of the spammers' access. Clio uses machine learning to detect emerging threats and highlight unusual chatbot usage, assisting Anthropic's trust and safety team. The company encourages other AI labs to adopt similar monitoring strategies to address potential harms while exploring diverse user applications.

[### Scaling Laws ‚Äì O1 Pro Architecture, Reasoning Training Infrastructure, Orion and Claude 3.5 Opus ‚ÄúFailures‚Äù (36 minute read)](https://semianalysis.com/2024/12/11/scaling-laws-o1-pro-architecture-reasoning-training-infrastructure-orion-and-claude-3-5-opus-failures/?utm_source=tldrai)

There's skepticism around AI scaling laws, citing challenges like data exhaustion and hardware limits, but major AI players like Amazon, Meta, and OpenAI are continuing massive investments in data center and custom silicon capabilities, signaling their faith in ongoing scaling potential. New paradigms beyond pre-training, such as synthetic data, Reinforcement Learning, and advanced fine-tuning, are helping overcome traditional scaling barriers. OpenAI's o1 release demonstrates that increasing test-time compute, leveraging multi-datacenter training, and exploring novel scaling dimensions can significantly enhance AI model capabilities.

‚ö°Ô∏è

### Quick Links

[### Google's new Jules AI agent will help developers fix buggy code (2 minute read)](https://www.theverge.com/2024/12/11/24318628/jules-google-ai-coding-agent-gemini-2-0-announcement?utm_source=tldrai)

Google Jules is an AI code agent designed to fix coding errors for Python and JavaScript in GitHub workflows.

[### Microsoft releases Phi-4 language model trained mainly on synthetic data (4 minute read)](https://siliconangle.com/2024/12/13/microsoft-releases-phi-4-language-model-trained-mainly-synthetic-data/?utm_source=tldrai)

Microsoft's new open-source language model, Phi-4, excels in solving math problems, outperforming even larger models like GPT-4o and Llama 3.3.

[### ChatGPT's new Projects feature can organize your AI clutter (4 minute read)](https://www.techradar.com/computing/artificial-intelligence/chatgpts-new-projects-feature-can-organize-your-ai-clutter?utm_source=tldrai)

OpenAI's new Projects feature for ChatGPT enhances interaction organization by grouping related chats and files within a named Project.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590657