Stable Video 3D üìπ, Apple‚Äôs multimodal AI breakthrough üëè, Nvidia‚Äôs new B100 chips üíæ

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2024-03-19

## Stable Video 3D üìπ, Apple‚Äôs multimodal AI breakthrough üëè, Nvidia‚Äôs new B100 chips üíæ

üöÄ

### Headlines & Launches

[### Anthropic Prompt Library (2 minute read)](https://docs.anthropic.com/claude/prompt-library?utm_source=tldrai)

The release of Claude 3 has been quite popular, but the prompting style for these models is slightly different. Anthropic has collected a set of user prompts that work well for a wide variety of tasks and topics.

[### Apple Researchers Achieve Breakthrough In Multimodal AI (3 minute read)](https://venturebeat.com/ai/apple-researchers-achieve-breakthroughs-in-multimodal-ai-as-company-ramps-up-investments/?utm_source=tldrai)

Apple researchers have developed methods for training large language models on both text and images, leading to state-of-the-art performance in multimodal AI tasks.

[### Stability AI releases Stable Video 3D (6 minute read)](https://stability.ai/news/introducing-stable-video-3d?utm_source=tldrai)

Built on top of Stable Video, Stable Video 3D can generate 3D models from a single image. It outperforms Stable Zero 123 and other methods. Weights are available for research purposes and commercial use with a Stability AI membership.

üß†

### Research & Innovation

[### Mechanics of Next Token Prediction with Self-Attention (40 minute read)](https://arxiv.org/abs/2403.08081?utm_source=tldrai)

Next token prediction is a simple objective that leads to complex behaviors. This work found that a single self attention layer trained with gradient descent broke the problem down into hard retrieval and soft composition, which enabled in-context learning and strong overall performance.

[### Enhancing Object Detection with Visual Transformers (11 minute read)](https://arxiv.org/abs/2403.09313v1?utm_source=tldrai)

YOLOX-ViT introduces a new approach to object detection in underwater robotics by integrating visual transformers and knowledge distillation.

[### Pretraining the same model with 16 different tokenizers (7 minute read)](https://github.com/alasdairforsythe/tokenmonster/blob/main/benchmark/pretrain.md?utm_source=tldrai)

A weird fact of modern language modeling is that we train a tokenizer first before training the model. The second weird fact is that vocab size doesn't seem to matter too much at large scales.

üë®‚Äçüíª

### Engineering & Resources

[### Google + Gretel Workshop: Use a fine-tuned LLM to anonymize financial data (Sponsor)](https://info.gretel.ai/anonymize-financial-data-workshop?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=032024-financeworkshop&amp;utm_content=tldr)

Speakers: Dr. Ali Arsanjani, Ph.D., Director of Engineering @ Google; Alex Watson, Co-Founder and Chief Product Officer @ Gretel; Maarten Van Segbroeck, Ph.D., Principal Applied Science @ Gretel

Time:[Monday, April 1st, at 1pm PT / 4pm ET](https://info.gretel.ai/anonymize-financial-data-workshop?utm_source=newsletter&utm_medium=email&utm_campaign=032024-financeworkshop&utm_content=tldr)

What: This workshop will showcase an [end-to-end machine learning approach](https://info.gretel.ai/anonymize-financial-data-workshop?utm_source=newsletter&utm_medium=email&utm_campaign=032024-financeworkshop&utm_content=tldr) to automatically anonymize sensitive customer data in financial documents, including:

* Generating synthetic training data
* Fine-tuning language models
* Deploying through a Streamlit application
* Enabling human-in-the-loop validation

[Register (FREE) to submit your questions early](https://info.gretel.ai/anonymize-financial-data-workshop?utm_source=newsletter&utm_medium=email&utm_campaign=032024-financeworkshop&utm_content=tldr)

[### Object Recognition Across Different Spectrums (GitHub Repo)](https://github.com/924973292/editor?utm_source=tldrai)

This project introduces a new method for identifying objects in images taken from various spectrums like RGB, near-infrared, and thermal imaging, focusing on object-centric information to overcome background noise and improve recognition accuracy.

[### LLM4Decompile (GitHub Repo)](https://github.com/albertan017/LLM4Decompile?utm_source=tldrai)

Decompile binary code with large language models.

[### 3D Scene Understanding (GitHub Repo)](https://github.com/dvlab-research/groupcontrast?utm_source=tldrai)

GroupContrast redefines self-supervised 3D representation learning by integrating segment grouping with semantic-aware contrastive learning.

üéÅ

### Miscellaneous

[### AI Prompt Engineering Is Dead (8 minute read)](https://spectrum.ieee.org/prompt-engineering-is-dead?utm_source=tldrai)

Recent studies suggest human prompt engineers may become obsolete as AI and machine learning models increasingly optimize their own prompts. Algorithmically generated prompts can be bizarre yet effective, outperforming human-crafted ones and reducing optimization time dramatically. While automatically tuned prompts show promise, experts believe that the demand for prompt-related jobs will evolve rather than disappear, potentially under new job titles like LLMOps (Large Language Model Operations).

[### Captain's log: the irreducible weirdness of prompting AIs (7 minute read)](https://bit.ly/3IHjxAX)

A new companion website, More Useful Things, offers a trove of free AI and machine learning resources, underlining the quirky and effective ways AI-generated prompts, like imaginative scenarios, can outperform human-crafted ones in tasks such as mathematical problem-solving. The experiment underscores the importance of adding context, few-shot learning, and chain-of-thought techniques for more consistent prompting results. As AI models advance, prompting as a skill may become less critical, with AI improving at inferring user intent, but currently, structured prompting remains an evolving art with significant potential benefits.

‚ö°Ô∏è

### Quick Links

[### TLDR readers: get Zendesk CRM and customer success tools for FREE for 6 months (Sponsor)](https://www.zendesk.com/lp/startup-partner/?ref=gen&amp;partner_account=0016R00003OlqXIQAZ&amp;utm_source=tldrai)

Every customer counts when you're a startup. Get free access to the tools you need to deliver exceptional customer experience. [Apply for 6 months free](https://www.zendesk.com/lp/startup-partner/?ref=gen&partner_account=0016R00003OlqXIQAZ)

[### Google Researchers Unveil An AI That Can Bring Still Videos To Life (3 minute read)](https://venturebeat.com/ai/google-researchers-unveil-vlogger-an-ai-that-can-bring-still-photos-to-life/?utm_source=tldrai)

VLOGGER is an AI created by Google researchers that generates lifelike videos of people speaking and moving from a single photo.

[### Microsoft has added the GPT-4 Turbo LLM to the free version of Copilot (2 minute read)](https://www.neowin.net/news/microsoft-has-added-the-gpt-4-turbo-llm-to-the-free-version-of-copilot/?utm_source=tldrai)

Copilot Pro users can still opt for the older model and they also have access to Copilot GPT Builder for creating custom chatbots without programming expertise.

[### Korean researchers power-shame Nvidia with new neural AI chip (4 minute read)](https://www.tomshardware.com/tech-industry/artificial-intelligence/korean-researchers-power-shame-nvidia-with-new-neural-ai-chip-claim-625-times-less-power-41-times-smaller?utm_source=tldrai)

KAIST researchers have developed the C-Transformer, an ultra-low-power AI chip for large language models that boasts significant energy efficiency improvements over Nvidia's A100 GPU.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590608