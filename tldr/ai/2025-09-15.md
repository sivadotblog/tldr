Grok 4 Fast ü§ñ, post-training 101 üìà, xAI layoffs üíº

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# Get smarter about AI in 5 minutes 2025-09-15

## Grok 4 Fast ü§ñ, post-training 101 üìà, xAI layoffs üíº

### 

[### Baseten Raises $150M Series D at $2.15B Valuation (Sponsor)](https://login.baseten.co/sign-up?state=eyJuZXh0X3VybCI6bnVsbH0%3A1ux5mS%3AXsp1P0NZdqAn3f98fbZutaudZRckgVFwBjEm2104XQM&amp;redirect_uri=https%3A%2F%2Fapp.baseten.co%2Fapi%2Fauth%2Fcallback&amp;authorization_session_id=01K4Z8Z8YNY3PJCZMHD66ARQ88/?utm_source=affiliates&amp;utm_medium=tldr_tech&amp;utm_campaign=9_15_primary_tldr&amp;utm_term=Series_D&amp;utm_content=newsletter)

As the next generation of AI applications comes to market, ambitious teams are turning to [Baseten for inference infra](https://login.baseten.co/sign-up?state=eyJuZXh0X3VybCI6bnVsbH0%3A1ux5mS%3AXsp1P0NZdqAn3f98fbZutaudZRckgVFwBjEm2104XQM&redirect_uri=https%3A%2F%2Fapp.baseten.co%2Fapi%2Fauth%2Fcallback&authorization_session_id=01K4Z8Z8YNY3PJCZMHD66ARQ88/?utm_source=affiliates&utm_medium=tldr_tech&utm_campaign=9_15_primary_tldr&utm_term=Series_D&utm_content=newsletter) that not only keeps up with but accelerates their innovation.

Fueled by the growth of customers like OpenEvidence, Abridge, Clay, Sourcegraph, Hex, and Zed, Baseten has announced a $150M Series D at a $2.15B valuation - just 6 months after a $75M Series C.

This funding will help the team meet surging demand and continue powering the fastest-growing AI companies. [Try them out here](https://login.baseten.co/sign-up?state=eyJuZXh0X3VybCI6bnVsbH0%3A1ux5mS%3AXsp1P0NZdqAn3f98fbZutaudZRckgVFwBjEm2104XQM&redirect_uri=https%3A%2F%2Fapp.baseten.co%2Fapi%2Fauth%2Fcallback&authorization_session_id=01K4Z8Z8YNY3PJCZMHD66ARQ88/?utm_source=affiliates&utm_medium=tldr_tech&utm_campaign=9_15_primary_tldr&utm_term=Series_D&utm_content=newsletter).

üöÄ

### Headlines & Launches

[### xAI Lays Off 500 Data Annotators (1 minute read)](https://techcrunch.com/2025/09/13/xai-reportedly-lays-off-500-workers-from-data-annotation-team/?utm_source=tldrai)

xAI has reportedly laid off a third of its data annotation team as it pivots to expand its specialized AI tutor division.

[### xAI launches Grok 4 Fast in early access beta with up to 10x speed (1 minute read)](https://www.testingcatalog.com/xai-launches-grok-4-fast-in-early-access-beta-with-up-to-10x-speed/?utm_source=tldrai)

Grok 4 Fast, the newest addition to xAI's lineup, is now available for users on the Grok web interface via the model selector. It can be accessed by enabling a new toggle in the Subscription settings. Marked as an early access beta, Grok 4 Fast is up to 10 times quicker than the standard Grok 4. It is optimized to respond rapidly by spending minimal processing time on complex tasks, which limits its creative abilities.

üß†

### Deep Dives & Analysis

[### Post-Training 101 for LLMs (39 minute read)](https://tokens-for-thoughts.notion.site/post-training-101?utm_source=tldrai)

A walkthrough of the entire post-training lifecycle of LLMs, from supervised fine-tuning and reward modeling to reinforcement learning methods such as RLHF, along with evaluation best practices.

[### The Vertical AI Playbook (Book)](https://research.contrary.com/deep-dive/the-vertical-ai-playbook?utm_source=tldrai)

Despite billions invested, 42% of enterprise AI initiatives were discontinued in 2024. This was caused by how models were embedded into business. The winners redesign workflows, rethink structures, and take ownership of the service layer where value is created. The next generation of CEOs will treat AI as a labor class and deploy the technology with the same discipline that the most successful serial acquirers apply to capital.

[### Breaking GPT-OSS: A brief investigation (6 minute read)](https://www.lesswrong.com/posts/HfXyF4swFLpeLuv3W/breaking-gpt-oss-a-brief-investigation?utm_source=tldrai)

This article evaluates different jailbreaking methods against gpt-oss. The model appears to have had robust safety training in both system prompting and refusal vector attacks. It is tricky to work with, and not all libraries support its idiosyncrasies.

üë®‚Äçüíª

### Engineering & Research

[### Gartner's latest Magic Quadrant compares the top cloud infrastructure providers (Sponsor)](https://cloud.google.com/resources/content/2025-gartner-magic-quadrant-strategic-cloud-platform-services?e=48754805&amp;hl=en&amp;utm_source=cloud_sfdc&amp;utm_medium=email&amp;utm_campaign=FY25-Q3-GLOBAL-ENT36283-website-dl-2025SCPSMQ-88982&amp;utm_content=tldr&amp;utm_term=september_15)

The [2025 Gartner¬Æ Magic Quadrant‚Ñ¢ for Strategic Cloud Platform Services](https://cloud.google.com/resources/content/2025-gartner-magic-quadrant-strategic-cloud-platform-services?e=48754805&hl=en&utm_source=cloud_sfdc&utm_medium=email&utm_campaign=FY25-Q3-GLOBAL-ENT36283-website-dl-2025SCPSMQ-88982&utm_content=tldr&utm_term=september_15) compares Google, Microsoft, Amazon, and 5 other leaders in cloud infrastructure. It looks at dozens of mandatory and common features that determine a vendor's ability to support mission-critical workloads. [Find out why Google was named a leader](https://cloud.google.com/resources/content/2025-gartner-magic-quadrant-strategic-cloud-platform-services?e=48754805&hl=en&utm_source=cloud_sfdc&utm_medium=email&utm_campaign=FY25-Q3-GLOBAL-ENT36283-website-dl-2025SCPSMQ-88982&utm_content=tldr&utm_term=september_15)

[### The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs (1 minute read)](https://arxiv.org/abs/2509.09677?utm_source=tldrai)

Real-world value often stems from the length of a task an agent can complete. Marginal gains in single-step accuracy can compound into exponential improvements in the length of a task a model can successfully complete. Models are more likely to make mistakes when the context contains errors from previous turns. Failures when tasks are made longer arise from mistakes in execution rather than an inability to reason.

[### The second wave of MCP: Building for LLMs, not developers (3 minute read)](https://vercel.com/blog/the-second-wave-of-mcp-building-for-llms-not-developers?utm_source=tldrai)

Teams that shift from API shaped tools to workflow-shaped tools see meaningful improvements in reliability and efficiency. MCP works best when tools handle complete user intentions rather than exposing individual API operations. Large language models don't work like developers - they have to constantly rediscover which tools exist, how to use them, and in what order, so building tools around workflows produces better results.

[### VaultGemma: The world's most capable differentially private LLM (11 minute read)](https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/?utm_source=tldrai)

VaultGemma is a model that Google trained from scratch with Differential Privacy (DP). DP offers a mathematically robust solution to user privacy that adds calibrated noise to present memorization. It has some trade-offs, like reducing training stability and significantly increasing batch size. There is still a utility gap between DP-trained and non-DP-trained models, but that gap can be systematically narrowed with more research on mechanism design for DP training.

üéÅ

### Miscellaneous

[### AI Will Not Make You Rich (35 minute read)](https://joincolossus.com/article/ai-will-not-make-you-rich/?utm_source=tldrai)

Most of the new value created by AI will be captured by consumers, who will see wider and more affordable access to services like medical care, education, and advice. Knowledge-intensive services will get cheaper, allowing consumers to buy more of them. At the same time, services that require person-to-person interaction will get more expensive and take up a greater percentage of household spending. There will be obvious opportunities in both. Think through the implications of knowledge workers becoming more efficient, imagine what markets this efficiency unlocks, and invest in those.

[### You should be rewriting your prompts (6 minute read)](https://maxleiter.com/blog/rewrite-your-prompts?utm_source=tldrai)

Models aren't perfectly interchangeable - if you are switching models, rewrite your prompts. Prompts overfit to models the same way models overfit to data. They need to be tested, evaluated, and aligned with the defaults of the new model. Adapting prompts will save tokens while producing better results.

‚ö°Ô∏è

### Quick Links

[### Warp announces Warp Code - the ultimate agentic development environment (Sponsor)](https://www.warp.dev/code?utm_source=publications&amp;utm_medium=newsletter&amp;utm_campaign=warp_code_9_15_quicklinks&amp;utm_content=tldr_ai)

Warp already beat Claude Code and Cursor in agent benchmarks. Now it has a nifty editor, code review, and other tools that make it the perfect AI coding environment. [Try Warp Code for free](https://www.warp.dev/code?utm_source=publications&utm_medium=newsletter&utm_campaign=warp_code_9_15_quicklinks&utm_content=tldr_ai)

[### Managing Agent Memory with Sessions (19 minute read)](https://cookbook.openai.com/examples/agents_sdk/session_memory?utm_source=tldrai)

How to manage short-term memory for AI agents using the OpenAI Agents SDK, employing trimming and compression techniques to keep sessions coherent, fast, and reliable.

[### Nvidia steps back from DGX Cloud ‚Äî stops trying to compete with AWS and Azure (2 minute read)](https://www.tomshardware.com/tech-industry/nvidia-steps-back-from-dgx-cloud?utm_source=tldrai)

Nvidia now uses its DGX Cloud capacity for internal research.

[### OpenAI Grove Program Announcement (1 minute read)](https://openai.com/index/openai-grove/?utm_source=tldrai)

OpenAI has announced a 5-week residency for early-stage technical founders, offering mentorship, early tool access, and peer collaboration to explore new AI product ideas.

[### Understanding GPU Architecture (35 minute read)](https://cvw.cac.cornell.edu/gpu-architecture?utm_source=tldrai)

Cornell's Center for Advanced Computing published an interactive workshop covering GPU memory hierarchies, streaming multiprocessors, and detailed breakdowns of NVIDIA's Tesla V100 and Quadro RTX 5000 architectures.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 620,000 readers for [one daily email](/api/latest/ai)

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1757982319