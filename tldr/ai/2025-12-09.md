State of enterprise AI üíº, Claude Code in Slack üíª, alignment is capability ‚öñÔ∏è¬†¬†

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2025-12-09

## State of enterprise AI üíº, Claude Code in Slack üíª, alignment is capability ‚öñÔ∏è

### 

[### $80M ARR in 7 months: How Lovable is turning AI pricing inside out (Sponsor)](https://metronome.com/webinars/monetization-operating-model-webinar-series?utm_campaign=monetization-wp&amp;utm_medium=newsletter&amp;utm_source=tldr-ai&amp;utm_content=)

Token pricing. Outcome-based value. Hybrid models. Every AI company is inventing their own pricing model because traditional SaaS economics don't apply when every user extracts wildly different value.

Elena Verna, Head of Growth at Lovable, is navigating this in real-time. She helped Lovable [hit $80M ARR in under seven months](https://metronome.com/webinars/monetization-operating-model-webinar-series?utm_campaign=monetization-wp&utm_medium=newsletter&utm_source=tldr-ai&utm_content=) with a lean team. On December 10, she's joining Metronome to share:

* [How Lovable experiments with pricing](https://metronome.com/webinars/monetization-operating-model-webinar-series?utm_campaign=monetization-wp&utm_medium=newsletter&utm_source=tldr-ai&utm_content=) to reflect delivered value
* What it takes to evolve from usage-based to outcomes-based pricing in practice
* What's actually working when navigating self-serve and enterprise monetization

[üëâ Happening tomorrow - last chance to join! Register now](https://metronome.com/webinars/monetization-operating-model-webinar-series?utm_campaign=monetization-wp&utm_medium=newsletter&utm_source=tldr-ai&utm_content=)

üöÄ

### Headlines & Launches

[### The state of enterprise AI (5 minute read)](https://openai.com/index/the-state-of-enterprise-ai-2025-report/?utm_source=tldrai)

OpenAI's state of the enterprise AI report shares a comprehensive look at how enterprises are adopting AI, what workers say they're gaining, and how organizational leaders are turning experimentation into measurable productivity and new capabilities. The analysis draws on real-world usage data from OpenAI's enterprise customers and a survey of over 9,000 workers across 100 enterprises. It is clear that enterprise adoption is accelerating in both breadth and depth. The technology is reshaping how people work, how teams collaborate, and how organizations build and deliver products.

[### Claude Code in Slack (3 minute read)](https://techcrunch.com/2025/12/08/claude-code-is-coming-to-slack-and-thats-a-bigger-deal-than-it-sounds/?utm_source=tldrai)

Anthropic is launching Claude Code in Slack, allowing devs to run full coding sessions directly from threads. With workflow automation, repo context detection, and progress updates, this shift embeds AI deeper into team collaboration rather than traditional IDEs.

üß†

### Deep Dives & Analysis

[### Alignment Is Capability (13 minute read)](https://www.off-policy.com/alignment-is-capability/?utm_source=tldrai)

Alignment research is part of the core research problem. Labs that treat alignment as a constraint will hit a ceiling, while those that figure out how to build models that genuinely understand human values will pull ahead. AGI requires alignment. The integrated approach looks like the strongest approach.

[### NVIDIA frenemy relation with OpenAI and Oracle (13 minute read)](https://philippeoger.com/pages/deep-dive-into-nvidias-virtuous-cycle?utm_source=tldrai)

Nvidia, OpenAI, and Oracle are all putting pressure on each other. If Nvidia stopped investing in OpenAI, OpenAI might not have the cash to sign that deal with Oracle. This might mean that Oracle wouldn't have the money to buy Nvidia's chips. Some of the companies' reported revenues might be more fragile than they look.

[### FSDP2 Training (19 minute read)](https://lmsys.org/blog/2025-12-03-miles-fsdp/?utm_source=tldrai)

This post explores backend alignment with Megatron, reinforcement learning improvements, speculative decoding with online SFT, and FP8 precision for scalable model training.

üë®‚Äçüíª

### Engineering & Research

[### 100 prompts for Notion Agents (Sponsor)](https://info.notion.so/resources/100-notion-ai-agent-use-cases?utm_source=newsletter&amp;utm_medium=TLDR&amp;utm_content=100-AI-agent-prompts&amp;utm_campaign=2025Q3-TLDRAI-100AgentPrompts)

Not sure how to use Notion Agents? Here are 100 [outcome-oriented examples](https://info.notion.so/resources/100-notion-ai-agent-use-cases?utm_source=newsletter&utm_medium=TLDR&utm_content=100-AI-agent-prompts&utm_campaign=2025Q3-TLDRAI-100AgentPrompts) with ‚ÄúAgent Steps‚Äù that show exactly how and what a Notion Agent will produce. Think dashboards databases, and reports, all organized by function (analytics, strategy, event planning, CX, and more). [Show me the prompts ‚Üí](https://info.notion.so/resources/100-notion-ai-agent-use-cases?utm_source=newsletter&utm_medium=TLDR&utm_content=100-AI-agent-prompts&utm_campaign=2025Q3-TLDRAI-100AgentPrompts)

[### Architecting Security for Agentic Capabilities in Chrome (15 minute read)](https://security.googleblog.com/2025/12/architecting-security-for-agentic.html?utm_source=tldrai)

Agentic browsers all face the threat of indirect prompt injection, which can appear anywhere and cause agents to take unwanted actions. Google has invested in a layered defense that includes both deterministic and probabilistic defenses to make it difficult and costly for attackers to cause harm. It created the user alignment critic, which vets an agent's actions using a separate model isolated from untrusted content. It also extended Chrome's origin-isolation capabilities to constrain what origins the agent can interact with.

[### Training a VLM Judge Without Human Labels (16 minute read)](https://arxiv.org/abs/2512.05145?utm_source=tldrai)

A new self-supervised framework trains vision-language model judges without human annotations by generating and filtering multimodal data through reasoning traces.

[### Debugging misaligned completions with sparse-autoencoder latent attribution (12 minute read)](https://alignment.openai.com/sae-latent-attribution/?utm_source=tldrai)

OpenAI researchers use interpretability tools to address misalignment in language models by employing sparse-autoencoders and latent attribution methods. The study introduced an attribution method to identify SAE latents likely causing certain behaviors, which proved more effective than activation-based methods in identifying causally relevant latents.

üéÅ

### Miscellaneous

[### Trump Promises Executive Order to Block State AI Regulations (4 minute read)](https://www.nytimes.com/2025/12/08/us/politics/trump-executive-order-ai-laws.html?unlocked_article_code=1.7U8.kJZo.FoW0WIgsMeCe&smid=url-share&utm_source=tldrai)

President Donald Trump said that he will be issuing an executive order this week to curb state laws on artificial intelligence. All 50 states and territories introduced AI legislation this year. Legal experts say that the President doesn't have the legal authority to intervene in state legislation. Eliminating state laws would effectively remove guardrails for AI.

[### Trump greenlights Nvidia H200 AI chip sales to China if US gets 25% cut, says Xi responded positively (3 minute read)](https://www.cnbc.com/2025/12/08/trump-nvidia-h200-sales-china.html?utm_source=tldrai)

Nvidia will be allowed to ship its H200 AI chips to approved customers in China and elsewhere on the condition that the US gets a 25% cut. The same approach will be applied to AMD, Intel, and other companies in the US. The policy change is aimed at supporting American jobs, strengthening US manufacturing, and benefiting American taxpayers. The Department of Commerce is still finalizing the details of the policy.

‚ö°Ô∏è

### Quick Links

[### Learn 7 MCP security best practices in 7 minutes (Sponsor)](https://www.wiz.io/lp/model-context-protocol-mcp-security-best-practices-cheat-sheet?utm_source=tldr-ai&amp;utm_medium=paid-email&amp;utm_campaign=FY26Q3_INB_FORM_MCP-BestPractices-Cheat-Sheet&amp;sfcid=701Py00000TCZuBIAX&amp;utm_term=FY26Q4-tldr-ai-quicklinks&amp;utm_content=MCP-Best-Practices)

Learn what security teams are doing to protect MCP and unlock 7 best practices you can start using today ‚Äì in <10 minutes. [Get the Wiz Cheat Sheet](https://www.wiz.io/lp/model-context-protocol-mcp-security-best-practices-cheat-sheet?utm_source=tldr-ai&utm_medium=paid-email&utm_campaign=FY26Q3_INB_FORM_MCP-BestPractices-Cheat-Sheet&sfcid=701Py00000TCZuBIAX&utm_term=FY26Q4-tldr-ai-quicklinks&utm_content=MCP-Best-Practices)

[### Agent Development Kit (ADK) for Rust (14 minute read)](https://docs.rs/adk-rust/0.1.4/adk_rust/?utm_source=tldrai)

adk\_rust is a flexible and modular framework for developing and deploying AI agents in Rust.

[### Horses (4 minute read)](https://andyljones.com/posts/horses.html?utm_source=tldrai)

Horses took two decades to phase out - AI probably won't give us that long.

[### Prediction: AI will make formal verification go mainstream (6 minute read)](https://martin.kleppmann.com/2025/12/08/ai-formal-verification.html?utm_source=tldrai)

AI-generated code needs formal verification to automate the review process and counteract the imprecise and probabilistic nature of LLMs.

[### LLMs Make Legal Advice Lossy (11 minute read)](https://writing.kemitchell.com/2025/12/07/LLMs-Make-Legal-Advice-Lossy?utm_source=tldrai)

Lawyers can tell when clients paste their advice into chatbots for summaries rather than reading what they write for them.

## Get the most interesting AI stories and breakthroughs delivered in a free daily email.

Subscribe

Join 920,000 readers for [one daily email](/api/latest/ai)

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1765292896