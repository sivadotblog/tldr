Ford self-driving division üöó, the rise of OpenAI CTO Mira Murati üìà, better control than ControlNet üï∏Ô∏è

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2023-03-03

## Ford self-driving division üöó, the rise of OpenAI CTO Mira Murati üìà, better control than ControlNet üï∏Ô∏è

üöÄ

### Headlines & Launches

[### Google cloud CEO rallying cry about continued AI competency (2 minute read)](https://archive.ph/GijmU?utm_source=tldrai)

With the AI race heating up, Google is feeling the pressure. In a recent internal meeting the Google Cloud CEO said ‚ÄúThe game is never over in the first minute‚Äù and urged employees to work as a team to continue to improve AI capabilities. He talked about what the history books would say about Google navigating this time period and expressed optimism about the future of search.

[### Ford announces new self driving division ‚ÄúLatitude AI‚Äù (3 minute read)](https://media.ford.com/content/fordmedia/fna/us/en/news/2023/03/02/ford-establishes-latitude-ai-to-develop-future-automated-driving.html?utm_source=tldrai)

Ford is committed to the future of autonomous vehicles and this announcement confirms that. The 550 person Pittsburgh based team will continue working on technologies that have shipped in Ford products while also doing long term research towards fully autonomous vehicles. Long standing leaders in the field will lead the group in various capacities.

üß†

### Research & Innovation

[### Long convolutions and clever token mixing scales to be 100x faster at 64k tokens (60 minute read)](https://arxiv.org/abs/2302.10866?utm_source=tldrai)

Another paper from the systems group at Stanford working on improving language modeling abilities for long context. They work to build a subquadratic attention replacement and build on much of their recent work in state space models and long convolutions work. They introduce the ‚ÄúHyena Hierarchy‚Äù which is a drop in replacement for attention, while reducing FLOPs, and improving long context scaling. This is an exciting next step and worth a read.

[### Unlimited-Size Diffusion Restoration (9 minute read)](https://arxiv.org/abs/2303.00354?utm_source=tldrai)

The paper discusses the use of diffusion models for zero-shot image restoration and proposes solutions for handling images of arbitrary sizes. The current methods only deal with fixed-size images, but the proposed approach uses Mask-Shift Restoration to address local incoherence and Hierarchical Restoration to alleviate out-of-domain issues. These parameter-free approaches can be used not only for image restoration but also for image generation of unlimited sizes, making them a potential general tool for diffusion models.

[### StraIT: Non-autoregressive Generation with Stratified Image Transformer (15 minute read)](https://arxiv.org/abs/2303.00750?utm_source=tldrai)

The paper proposes a non-autoregressive (NAR) generative model called Stratified Image Transformer (StraIT) that outperforms existing autoregressive (AR) and diffusion models (DMs) in high-quality image synthesis. StraIT leverages the hierarchical nature of images to encode visual tokens into stratified levels, which alleviates modeling difficulty and lifts the generative power of NAR models. The experiments show that StraIT achieves FID scores of 3.96 at 256√ó256 resolution on ImageNet without leveraging any guidance in sampling or auxiliary image classifiers.

üë®‚Äçüíª

### Engineering & Resources

[### Monocular Depth Estimation using Diffusion Models (Github Repo)](%E2%80%8B%E2%80%8Bhttps://depth-gen.github.io/?utm_source=tldrai)

The authors propose a denoising diffusion model-based approach for monocular depth estimation. They introduce innovations to tackle noisy and incomplete depth maps, and leverage pre-training for supervised learning. Their DepthGen model achieves state-of-the-art performance and represents depth ambiguity naturally. The model's imputation support and zero-shot performance enable a simple text-to-3D pipeline.

[### Better control than ControlNet (HuggingFace Space)](https://huggingface.co/spaces/weizmannscience/multidiffusion-region-based?utm_source=tldrai)

Another novel approach to controlling the geometric output of a text-to-image model. This time you can specify multiple regions to control. The general code is not yet available, but you can test the model out in this space.

[### Collage Diffusion: Precise Control over Collage-Conditional Image Generation (25 minute read)](https://arxiv.org/abs/2303.00262?utm_source=tldrai)

The paper proposes Collage Diffusion, a collage-conditional diffusion algorithm that enables precise control over the spatial arrangement and visual attributes of objects in generated images. By modifying the text-image cross-attention with alpha masks and learning specialized text representations per layer, users can edit individual components of generated images and control image harmonization on a layer-by-layer basis. Collage Diffusion generates globally harmonized images that maintain desired object locations and visual characteristics better than prior approaches.

üéÅ

### Miscellaneous

[### 20B Flan UL2 Model released - fully open source with no restrictions (7 minute read)](https://www.yitay.net/blog/flan-ul2-20b?utm_source=tldrai)

With a context length of 2048 tokens, this instruction tuned model is an excellent foundation model for text generation. With improved CoT, in context learning, and general performance (as much as 7.4% over FlanT5-xxl) this model is a great step forward in open source language models. This model uses the UL2 objective which is a mixture of denoisers and has shown impressive performance at general language modeling. Importantly, they also remove the need for cumbersome mode tokens by an additional 100k steps of training before the Flan instruction tuning process.

[### Inside the rise of OpenAI CTO Mira Murati (17 minute read)](https://archive.is/9t9gB?utm_source=tldrai)

This article is a deep dive into how OpenAI CTO Mira Murati became one of tech‚Äôs most influential innovators.

[### EleutherAI retrospective (6 minute read)](https://blog.eleuther.ai/year-two-preface/?utm_source=tldrai)

One of the top open science collaboratives in ML, Eleuther has made many contributions to the field over the past year and a half. They have published 28 papers, 10 different models, and dozens of code bases. Many of the most exciting developments such as RWKV, GPTNeo, and open replications of AlphaFold are coming from this group. Read more here about what they‚Äôre working on and what‚Äôs coming next.

‚ö°Ô∏è

### Quick Links

[### OpenAI pricing thread (Twitter Thread)](https://threadreaderapp.com/thread/1631346679893958658.html?utm_source=tldrai)

Yesterday‚Äôs 90% price drop on the ChatGPT API ‚Äì aka "gpt-3.5-turbo" ‚Äì is another before & after moment in AI.

[### PromptCraft-Robotics (GitHub Repo)](https://github.com/microsoft/PromptCraft-Robotics?utm_source=tldrai)

PromptCrafts-Robotics is a community for people to test and share interesting prompting examples for LLMs within the robotics domain.

[### Romania unveils world‚Äôs first AI government ‚Äúadvisor‚Äù (2 minute read)](https://interestingengineering.com/innovation/romania-unveils-worlds-first-ai-advisor?utm_source=tldrai)

The Romanian government has unveiled "Ion," an artificial intelligence (AI) based platform built to record Romanians' voices and opinions and use them to guide state policy decisions.

[### Nebullvm (GitHub Repo)](https://github.com/nebuly-ai/nebullvm?utm_source=tldrai)

Nebullvm is an ecosystem of plug and play modules to optimize the performance of your AI systems.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590542