OpenAI GPT 4.1 üöÄ, Hugging Face acquires Pollen Robotics ü§ñ, DolphinGemma üê¨

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2025-04-15

## OpenAI GPT 4.1 üöÄ, Hugging Face acquires Pollen Robotics ü§ñ, DolphinGemma üê¨

### 

[### Delve goes viral on X for pulling all-nighters to ship autopilot for SOC 2 (Sponsor)](https://x.com/karunkaushik_/status/1911099962869629262)

Delve officially launched Computer Use Agents that allow founders and GRC teams to go auto-capture all screenshots for SOC 2.

And customers are using it to achieve incredible results:

* Lovable got fully SOC 2 compliant in less than 20 hours
* 11x ditched their old compliance platform, [saved 143 hours on SOC 2](https://www.delve.co/case-study/11x-soc2-compliance-success-delve?utm_source=tldr&utm_medium=newsletter&utm_campaign=ai-apr15), and unlocked $1.2M ARR
* Bland AI got SOC 2 and unlocked $500k ARR within 7 days

If you want to ditch your old platform, they'll even migrate you off for FREE.

[Book a demo here](https://www.delve.co/book-demo?utm_source=tldr&utm_medium=newsletter&utm_campaign=ai_apr15) for $2000 off compliance in April!

(PS: TLDR readers get free custom Arc'teryx jackets)

üöÄ

### Headlines & Launches

[### OpenAI GPT-4.1 (12 minute read)](https://openai.com/index/gpt-4-1/?utm_source=tldrai)

OpenAI has launched three new models in its API: GPT‚Äë4.1, GPT‚Äë4.1 mini, and GPT‚Äë4.1 nano. These models outperform GPT‚Äë4o and GPT‚Äë4o mini across the board, with major gains in coding and instruction following. They also have larger context windows‚Äîsupporting up to 1 million tokens of context‚Äîand are able to better use that context with improved long-context comprehension. They feature a refreshed knowledge cutoff of June 2024.

[### DolphinGemma (6 minute read)](https://blog.google/technology/ai/dolphingemma/?utm_source=tldrai)

DeepMind has announced DolphinGemma, a large language model developed by Google that helps scientists study how dolphins communicate ‚Äî and hopefully find out what they're saying, too.

[### Hugging Face Acquires Pollen Robotics (4 minute read)](https://fortune.com/2025/04/14/ai-company-hugging-face-buys-humanoid-robot-company-pollen-robotics-reachy-2/?utm_source=tldrai)

Hugging Face, the center of the open source AI community, has long stated its goal is to be a decentralized DeepMind. While this isn't exactly the case, adding in an open source robotics platform via Pollen moves it closer to that goal.

üß†

### Research & Innovation

[### Seaweed-7B: Cost-Effective Training of Video Generation Foundation Model (21 minute read)](https://seaweed.video/?utm_source=tldrai)

The ByteDance team has released a paper showing how to train a competitive 7B parameter video generation model on a ‚Äúmodest‚Äù compute budget of 655k H100 hours. It has strong performance on a number of temporally difficult tasks.

[### PixelFlow: Pixel-Space Generative Models with Flow (30 minute read)](https://arxiv.org/abs/2504.07963?utm_source=tldrai)

Most generative models on continuous signals operate in latent space due to computational constraints. This work introduces a series of cascades that allow the generation to happen directly in pixel space. This eliminates the need for a pretrained VAE.

[### InteractVLM: 3D Interaction Reasoning from 2D Foundational Models (24 minute read)](https://arxiv.org/abs/2504.05303?utm_source=tldrai)

New VLM that can reason about contacts between humans in 3D and objects. It does so by leveraging a strong base model and lifting its reasoning into 3D with clever multi-view rendering.

üë®‚Äçüíª

### Engineering & Resources

[### Visual Reasoning with Less Data (16 minute read)](https://arxiv.org/abs/2504.07934v1?utm_source=tldrai)

Using MCTS to quantify sample difficulty, ThinkLite-VL improves reasoning in VLMs with just 11k training samples and no distillation.

[### Improved MoE with C3PO (GitHub Repo)](https://github.com/tianyi-lab/c3po?utm_source=tldrai)

C3PO introduces a new test-time optimization technique that improves accuracy in Mixture-of-Experts LLMs by re-mixing expert weights based on similar reference samples.

[### 3B parameter tokenizer (GitHub Repo)](https://github.com/SilentView/GigaTok?utm_source=tldrai)

Scaling up image tokenizers is challenging because they tend to collapse. This work introduces GigaTok, which is a massive tokenizer with superior reconstruction performance. Decoder scaling and regularization helped with stability and overall quality.

üéÅ

### Miscellaneous

[### 6 highlights from Google Cloud Next 25 (2 minute read)](https://blog.google/products/google-cloud/google-cloud-next-25-recap/?utm_source=tldrai)

Vertex AI introduces updates to video, image, speech, and music generation models, enhancing creative workflows for businesses. Google AI is enabling specialized AI agents for companies, improving productivity and security. A new Agent2Agent Protocol allows different AI agents to securely communicate across platforms.

[### Business Leaders' Thoughts on AI Possibilities (6 minute read)](https://blog.google/products/google-cloud/business-leaders-building-with-ai/?utm_source=tldrai)

Executives from nine companies share how they're leveraging Google Cloud's AI tools to drive innovation across sectors, with over 600 real-world use cases highlighted.

[### BrowseComp Benchmark for Hard-to-Find Knowledge (9 minute read)](https://openai.com/index/browsecomp/?utm_source=tldrai)

OpenAI's BrowseComp is a new benchmark of 1,266 problems designed to evaluate AI agents' browsing skills in gathering complex, hard-to-locate information online.

‚ö°Ô∏è

### Quick Links

[### Gemini Adds Question Generation to Google Classroom (1 minute read)](https://workspaceupdates.googleblog.com/2025/04/use-gemini-in-google-classroom-to-generate-questions-from-text.html?utm_source=tldrai)

Educators can now use Gemini to generate questions or quizzes from selected text in Google Classroom, enhancing lesson interactivity and streamlining content creation.

[### NVIDIA to Manufacture AI Supercomputers in the U.S. (12 minute read)](https://blogs.nvidia.com/blog/nvidia-manufacture-american-made-ai-supercomputers-us/?utm_source=tldrai)

NVIDIA is localizing AI hardware production by building factories in Texas and Arizona, aiming to produce Blackwell chips and AI supercomputers entirely within the U.S.

[### DeepSeek to Open Source its Inference Engine (2 minute read)](https://github.com/deepseek-ai/open-infra-index/blob/main/OpenSourcing_DeepSeek_Inference_Engine/README.md?utm_source=tldrai)

DeepSeek's inference engine is built on VLLM, although it is now heavily modified.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744763175