Meta AI Segment Anything üñºÔ∏è, OpenAI‚Äôs approach to AI safety ü¶∫, audio editing with diffusion models üîä

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2023-04-06

## Meta AI Segment Anything üñºÔ∏è, OpenAI‚Äôs approach to AI safety ü¶∫, audio editing with diffusion models üîä

### 

[### Effortlessly convert ML to optimized C++ for edge devices with Python (Sponsor)](https://www.edgeimpulse.com/blog/unveiling-the-new-edge-impulse-python-sdk?utm_source=newsletter&amp;utm_medium=email&amp;utm_campaign=tldr_ai)

You ML practitioners are the experts when it comes to developing and training models. But generating models that can deploy to edge devices remains a challenge.

To remedy that, we've launched the Edge Impulse Python SDK, providing the long-missing bridge between ML engineers and edge devices.

Access the power of Edge Impulse directly in your dev environment. Get on-device performance, optimize your model, and export a C++ library that can be deployed to any edge hardware.

Edge Impulse is used by top enterprises. Now it's easier than ever.

Try it at [edgeimpulse.com/BYOM](https://www.edgeimpulse.com/blog/unveiling-the-new-edge-impulse-python-sdk?utm_source=newsletter&utm_medium=email&utm_campaign=tldr_ai)

üöÄ

### Headlines & Launches

[### Google reveals its newest A.I. supercomputer, says it beats Nvidia (2 minute read)](https://www.cnbc.com/2023/04/05/google-reveals-its-newest-ai-supercomputer-claims-it-beats-nvidia-.html?utm_source=tldrai)

Google has developed a TPU-based supercomputer, called TPU v4, which it claims is 1.2x-1.7x faster and uses 1.3x-1.9x less power than Nvidia's A100 chips. The system, comprising over 4,000 Tensor Processing Units (TPUs), has been operational since 2020 and was used to train Google's PaLM model. The growing power requirements of AI continue to drive innovation in the chip industry and benefit cloud providers like Google, Microsoft, and Amazon, which rent out processing power and provide resources to startups.

[### Segment Anything, major advance in image segmentation (6 minute read)](https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/?utm_source=tldrai)

Image Segmentation is the process of pulling out all the pixels in an image that represent a certain object (e.g., a person or desk). It is a hard task for a few reasons, normally it either requires a huge dataset of predefined objects or some weak supervision. This new, fully open sourced, model from Meta feels like a leap forward in capabilities. They collected a massive dataset, made easier annotation features, and created a model that can run in your browser in real-time. Demo, code, and paper are available.

üß†

### Research & Innovation

[### A Survey of Large Language Models (25 minute read)](https://arxiv.org/abs/2303.18223?utm_source=tldrai)

This paper discusses the evolution of language modeling for artificial intelligence algorithms, with a focus on recent advances in large language models (LLMs) with billions of parameters. The paper offers a comprehensive review of LLMs, including pre-training, adaptation tuning, utilization, and capacity evaluation, and provides a useful resource for researchers and engineers.

[### What happens to models as they train? (33 minute read)](https://arxiv.org/abs/2304.01373?utm_source=tldrai)

The Pythia paper from EleutherAI is finally here! They released hundreds of checkpoints of Transformer models over time as they train. This is useful because it is not at all clear what skills models gain over time, but now the community can inspect the dynamics of training and gain massive insights into potential areas for improvement and efficiency.

[### AUDIT: Audio Editing by Following Instructions with Latent Diffusion Models (20 minute read)](https://audit-demo.github.io/?utm_source=tldrai)

AUDIT is a new instruction-guided audio editing model based on latent diffusion models, which can automatically modify only the necessary audio segments and only requires edit instructions instead of full target audio descriptions as text input. The proposed model achieved state-of-the-art results in both objective and subjective metrics for several audio editing tasks, including adding, dropping, replacement, inpainting, and super-resolution.

üë®‚Äçüíª

### Engineering & Resources

[### Basics of LLMs (7 minute read)](https://vinija.ai/models/LLM/?utm_source=tldrai)

This tutorial talks about the basics of large language models.

[### Lyft2vec: Embeddings at Lyft (9 minute read)](https://eng.lyft.com/lyft2vec-embeddings-at-lyft-d4231a76d219?utm_source=tldrai)

This post explains how graph learning methods are utilized at Lyft to generate embeddings, which are compact vector representations of high-dimensional information, and how these embeddings can reveal insights into riders, drivers, locations, and time in the rideshare industry.

[### Vocode (GitHub Repo)](https://github.com/vocodedev/vocode-python?utm_source=tldrai)

Vocode is an open source library that makes it easy to build voice-based LLM apps.

üéÅ

### Miscellaneous

[### Where Are AI Videos Going? (4 minute read)](https://archive.ph/Q1h1h?utm_source=tldrai)

AI-generated videos are gaining popularity, often depicting surreal scenes or celebrity memes. The technology's rapid advancement raises questions about its potential in Hollywood, such as casting movies or modeling scenes. Although challenges remain, experts believe AI will have a significant impact on content creation, but it won't replace human talent in the film industry anytime soon.

[### Neural Networks: Zero To Hero (Online Course)](https://karpathy.ai/zero-to-hero.html?utm_source=tldrai)

A course by Andrej Karpathy on building neural networks, from scratch, in code.

[### Our approach to AI Safety (6 minute read)](https://openai.com/blog/our-approach-to-ai-safety?utm_source=tldrai)

OpenAI is leading the way in capabilities research, they also are a strong player in developing safety systems for their language models. They outline a few directions they are tackling such as factuality, child safety, privacy, and more. They have made progress on all of these aims and the fact that GPT-4 was finished training 6 months before its launch, but held back to focus on safety concerns is interesting. The biggest take away here is that GPT-4 is 40% less likely to generate factually incorrect output than gpt-3.5-turbo.

‚ö°Ô∏è

### Quick Links

[### Imagica AI (Product)](https://twitter.com/glebich/status/1643121195523637249?utm_source=tldrai)

Build a no-code AI app in minutes.

[### Meta To Debut Ad-Creating Generative AI This Year (1 minute read)](https://asia.nikkei.com/Business/Technology/Meta-to-debut-ad-creating-generative-AI-this-year-CTO-says?utm_source=tldrai)

Facebook owner Meta intends to commercialize its proprietary generative artificial intelligence by December, joining Google in finding practical applications for the tech.

[### Australian Mayor May Sue ChatGPT (2 minute read)](https://interestingengineering.com/culture/australian-mayor-sue-chatgpt?utm_source=tldrai)

An Australian mayor has threatened to sue OpenAI for false allegations that he served time in prison for bribery.

[### Snapchat Adds New Safeguards For It‚Äôs AI Chatbot (2 minute read)](https://techcrunch.com/2023/04/05/snapchat-adds-new-safeguards-around-its-ai-chatbot/?utm_source=tldrai)

Snapchat is launching new tools, including an age filter and insights for parents, to improve its AI chatbot.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590548