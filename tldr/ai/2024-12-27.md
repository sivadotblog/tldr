Google Gemini & Anthropic Claude ü§ù, Hallucinatory AI Helps Science üí≠, Training AIs on User Feedback ü§ñ

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR AI 2024-12-27

## Google Gemini & Anthropic Claude ü§ù, Hallucinatory AI Helps Science üí≠, Training AIs on User Feedback ü§ñ

üöÄ

### Headlines & Launches

[### Google Gemini is using Claude to improve its AI (3 minute read)](https://techcrunch.com/2024/12/24/google-is-using-anthropics-claude-to-improve-its-gemini-ai/?utm_source=tldrai)

Google contractors are comparing Gemini AI's responses with Anthropic's Claude, but it's unclear if Google has permission to use Claude for testing. The contractors noted that Claude prioritizes safety in its responses more than Gemini. Google states that while it evaluates model outputs against competitors, it does not train Gemini on Anthropic's models.

[### AI Models Are Getting Smarter. New Tests Are Racing to Catch Up (13 minute read)](https://time.com/7203729/ai-evaluations-safety/?utm_source=tldrai)

AI systems are rapidly advancing, outperforming expectations on new challenging evaluations, like Epoch AI's FrontierMath. Despite this progress, designing effective evals to understand and manage AI capabilities remains complex and underfunded. Experts stress the need for sophisticated, timely tests to monitor potential risks as models evolve.

[### How Hallucinatory A.I. Helps Science Dream Up Big Breakthroughs (10 minute read)](https://www.nytimes.com/2024/12/23/science/ai-hallucinations-science.html?unlocked_article_code=1.j04.8joc.--6KOPzgYLxg&smid=url-share&utm_source=tldrai)

AI hallucinations, often criticized for inaccuracies, are proving valuable in scientific research by accelerating idea generation and discovery processes. Notable achievements include Nobel Prize-winning protein designs and innovations in antibiotic development and catheter design. Despite controversies around the term "hallucinations," experts acknowledge AI's potential for groundbreaking scientific insights.

üß†

### Research & Innovation

[### Efficient and robust safety architecture (7 minute read)](https://ai.meta.com/blog/meta-fair-updates-agents-robustness-safety-architecture/?utm_source=tldrai)

Meta has released an updated agents framework to measure and ensure robustness and safety when deployed in the wild.

[### Material Transformations Across Scenes (18 minute read)](https://arxiv.org/abs/2411.08037v1?utm_source=tldrai)

This research introduces a technique for applying material transformations, like wetness or coating, across different scenes using disentangled Neural Radiance Fields (NeRF).

[### The Risks of Training AIs on User Feedback (21 minute read)](https://arxiv.org/abs/2411.02306v1?utm_source=tldrai)

Researchers explored the consequences of training AI language models to optimize for user feedback, like thumbs up ratings. The study shows that this approach can lead to manipulation as AIs learn to game the system.

üë®‚Äçüíª

### Engineering & Resources

[### A Benchmark for Federated Learning in LLMs (GitHub Repo)](https://github.com/1xbq1/fedmllm?utm_source=tldrai)

A new benchmark evaluates the federated fine-tuning of MLLMs across diverse scenarios, including two datasets, five baselines, and over ten types of multimodal heterogeneities.

[### Prompt Tuning Playbook (GitHub Repo)](https://github.com/varungodbole/prompt-tuning-playbook?utm_source=tldrai)

A helpful guide for prompt engineering.

[### Metal Puzzles (GitHub Repo)](https://github.com/abeleinin/Metal-Puzzles?utm_source=tldrai)

A number of puzzles and tutorials to learn GPU programming on Mac Metal acceleration.

üéÅ

### Miscellaneous

[### AI Godmother Fei-Fei Li Has a Vision for Computer Vision (8 minute read)](https://spectrum.ieee.org/fei-fei-li-world-labs?utm_source=tldrai)

Fei-Fei Li's startup, World Labs, aims to enhance AI with 3D spatial intelligence to generate and interact with 3D worlds. The focus on spatial intelligence is crucial for advancing AI capabilities in both real and virtual 3D environments. This technology could revolutionize sectors like robotics, design, and augmented reality.

[### The AI revolution is running out of data. What can researchers do? (8 minute read)](https://www.nature.com/articles/d41586-024-03990-2?utm_source=tldrai)

AI development faces a data shortage crisis, projected to hit by 2028, as training data sizes approach the total stock of public online text. AI companies like OpenAI are exploring solutions such as generating new data and using unconventional sources to mitigate this issue. This data crunch may shift focus toward smaller, specialized AI models rather than large-scale LLMs.

[### Red Rabbit Robotics offers human-like robots as a service (6 minute read)](https://www.theregister.com/2024/12/15/red_rabbit_robotics/?utm_source=tldrai)

Red Rabbit Robotics is advancing the field of autonomous labor by developing and open-sourcing the RX1 robot for manufacturing and commercial applications. It aims to tap into the labor shortage by providing cost-effective, robotic solutions for dull, dangerous, and dirty jobs. The company's goal is to make robots more accessible at a lower price point and gradually transition from teleoperation to full autonomy, prioritizing utility and widespread adoption.

‚ö°Ô∏è

### Quick Links

[### Klarna's CEO says it stopped hiring thanks to AI but still advertises many open positions (3 minute read)](https://techcrunch.com/2024/12/14/klarnas-ceo-says-it-stopped-hiring-thanks-to-ai-but-still-advertises-many-open-positions/?utm_source=tldrai)

Klarna CEO Sebastian Siemiatkowski claims generative AI has enabled a workforce reduction, though the company is still hiring for essential roles.

[### Are LLMs capable of non-verbal reasoning? (5 minute read)](https://arstechnica.com/ai/2024/12/are-llms-capable-of-non-verbal-reasoning/?utm_source=tldrai)

Researchers at Meta and UC San Diego are developing LLMs that process logical solutions in "latent space," bypassing natural language constraints.

[### Quick takes on the recent OpenAI public incident write-up (5 minute read)](https://surfingcomplexity.blog/2024/12/14/quick-takes-on-the-recent-openai-public-incident-write-up/?utm_source=tldrai)

OpenAI's Kubernetes incident on December 11 was caused by unexpected interactions, where a new telemetry service overloaded the Kubernetes API servers, leading to failures in DNS-based service discovery.

## The most important AI, ML, and data science news in a free daily email.

Subscribe

Join 500,000 readers for one daily email

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/ai/advertise)

Timestamp: 1744590658