From Dashboards to Agents ü§ñ, Preventing Categorical Leakage üõ°Ô∏è, Vectorizing SQL üìê

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR Data 2025-12-15

## From Dashboards to Agents ü§ñ, Preventing Categorical Leakage üõ°Ô∏è, Vectorizing SQL üìê

üì±

### Deep Dives

[### Spectral Community Detection in Clinical Knowledge Graphs (22 minute read)](https://towardsdatascience.com/spectral-community-detection-in-clinical-knowledge-graphs/?utm_source=tldrdata)

Graph algorithms can be layered with spectral methods to reveal deep, clinically meaningful structural insights in patient populations that traditional clustering would miss. Given a graph dataset of patients, diseases, and relationships, the Leiden algorithm can identify distinct communities, spectral analysis adds intra-community signal to quantify cohesion, and the Fiedler vector cleanly splits ‚Äúmixed‚Äù communities. This pattern turns KGs into measurable, comparable cohort-structure features for exploratory analytics and GraphRAG-style enrichment. The code is available in the linked GitHub repository.

[### How to Measure Similarity Between SQL Queries Using Embeddings (6 minute read)](https://levelup.gitconnected.com/how-to-measure-similarity-between-sql-queries-using-embeddings-36a74b4beabf?utm_source=tldrdata)

Transforming SQL queries into vector embeddings enables precise, quantifiable measurement of query similarity, improving visibility into user behaviors and data access patterns in data lakes. Using sentence transformers (eg. all-MiniLM-L6-v2) to create embeddings and a vector database backend, queries are efficiently clustered, compared via cosine similarity, and visualized using methods like t-SNE to reduce dimensionality, revealing patterns such as tight clusters and outliers. This approach reduces guesswork in SQL optimization and workload analysis. Code linked in the article.

[### How We Made 100M Vector Indexing in 20 Minutes Possible on PostgreSQL (13 minute read)](https://blog.vectorchord.ai/how-we-made-100m-vector-indexing-in-20-minutes-possible-on-postgresql?utm_source=tldrdata)

VectorChord shows that 100M-scale vector indexing on PostgreSQL is practical without GPUs, reducing build time to ~20 minutes and memory to ~12 GB versus ~40 hours and ~200 GB with pgvector. The gains come from hierarchical K-means with dimensionality reduction and deep Postgres contention and parallelism optimizations, enabling low-cost, billion-scale vector search with minimal recall loss.

üöÄ

### Opinions & Advice

[### Dashboards Were Never the Destination (8 minute read)](https://hex.tech/blog/dashboards-were-never-the-destination/?utm_source=tldrdata)

Dashboards were a workaround for limited tools. They provide visibility but not real analysis. ‚ÄúSelf-service‚Äù plateaued because dashboards cannot reason or investigate. Agentic analytics shifts data teams from building static artifacts to curating context and logic, enabling systems that deliver real answers directly on the warehouse.

[### Opinionated Data Platforms vs. Open-Source: The Chef's Choice for Your Data Platform (13 minute read)](https://www.ssp.sh/blog/omakase-data-stack/?utm_source=tldrdata)

Market consolidation is accelerating a shift from open, composable data stacks to unified, opinionated data platforms that deliver immediate end-to-end analytics, automated orchestration, and robust DevOps integration out of the box. These platforms significantly reduce the need for manual infrastructure management, integration, and troubleshooting, focusing teams on delivering business value rather than tool-wrangling. Open standards such as Iceberg, Delta Lake, and Apache Arrow remain crucial, ensuring portability and mitigating vendor lock-in even within closed-source platforms. Deploy open-source stacks when maximum flexibility is required, but leverage opinionated platforms for operational simplicity, rapid time-to-value, and seamless scaling.

[### AI Agents Create a New Dimension for Database Scalability (7 minute read)](https://thenewstack.io/ai-agents-create-a-new-dimension-for-database-scalability/?utm_source=tldrdata)

The rise of AI agentic systems introduces a new scalability axis for databases: the ability to spawn and manage trillions of isolated, ephemeral database instances with microsecond provisioning and strict data isolation. Traditional multitenancy is giving way to hyper-tenancy, demanding in-process databases like SQLite, Turso, and DuckDB that offer instant instantiation, encryption, and vector-native operations. This architecture shift enables agents to fulfill dynamic, privacy-preserving data needs at hyperscale, transforming database design and operational paradigms for data-intensive organizations.

üíª

### Launches & Tools

[### Become an AI data engineer in 10 minutes with Bruin: the AI data vibeline (Sponsor)](https://getbruin.com/?utm_source=tldr&amp;utm_medium=sp&amp;utm_campaign=founders_202511)

Vibe coding doesn't work for data? It does now: [Bruin](https://github.com/bruin-data/bruin) is a command-line data tool that lets you build SQL & Python pipelines with built-in quality checks, column-level lineage, and end-to-end observability. It's open source, built in Go, and combines all the best parts of dbt + Airflow (minus the aggravation). [Build your first data vibeline](https://getbruin.com/?utm_source=tldr&utm_medium=sp&utm_campaign=founders_202511)

[### Introducing pg\_clickhouse: A Postgres Extension for Querying ClickHouse (5 minute read)](https://clickhouse.com/blog/introducing-pg_clickhouse?utm_source=tldrdata)

pg\_clickhouse v0.1.0, a PostgreSQL extension with near-universal query pushdown, enables seamless execution of analytics queries on ClickHouse directly from PostgreSQL, dramatically simplifying migration of analytical workloads. Supporting advanced pushdown for aggregates, FILTER expressions, and SEMI-JOINs, the extension streamlines moving from Postgres to ClickHouse, achieving sub-second TPC-H query execution in 21 of 22 cases. This eliminates costly query rewrites and leverages ClickHouse's high-performance engine for SQL-based analytics.

[### Announcing Magika 1.0: Now Faster, Smarter, and Rebuilt in Rust (5 minute read)](https://opensource.googleblog.com/2025/11/announcing-magika-10-now-faster-smarter.html?utm_source=tldrdata)

Google's Magika 1.0, now rebuilt in Rust, delivers AI-driven file type detection with support for over 200 formats‚Äîdoubling coverage, with substantial gains in distinguishing nuanced text, code, and data science files. Leveraging a 3TB+ training set and ONNX Runtime, Magika scans nearly 1,000 files/sec/core on modern CPUs while achieving ~99% precision and recall. Enhanced granularity and robust memory safety significantly improve pipeline reliability.

[### What it Means to Get Your Data Ready for AI (7 minute read)](https://ai.gopubby.com/what-it-means-to-get-your-data-ready-for-ai-518861a8f025?utm_source=tldrdata)

Agentic AI shifts data engineering from feeding rigid dashboards to enabling agents that turn user intent into actions. Five recommendations: favor business context over deep normalization; curate a small, high-quality ‚Äúexample store‚Äù for in-context learning; expose tool-ready APIs and semantically friendly formats; manage agent outputs as versioned first-class data; and connect observability to automated retraining. Net: build a flexible, auditable platform where agents can compose workflows.

üéÅ

### Miscellaneous

[### DBOS: 2025 Year in Review with Mike Stonebraker and Andy Pavlo (1 hour video)](https://www.youtube.com/watch?v=RnQKluxWB5Y&amp;t=7s&amp;utm_source=tldrdata)

LLMs perform well on public SQL benchmarks but fail on real enterprise warehouses, with accuracy near zero in private tests and only ~30% even with RAG or decomposition. As AI-generated code increasingly touches databases, the stack is shifting toward agentic, ACID-durable systems with holistic autotuning, while Postgres consolidation and native vector support are eroding the standalone vector-database moat.

[### Why XGBoost and LightGBM Are Secretly Leaking Your Data (and How CatBoost Fixes it) (2 minute read)](https://www.linkedin.com/feed/update/urn:li:activity:7405691431547195392?utm_source=tldrdata)

CatBoost avoids a common but underdiscussed source of leakage in XGBoost and LightGBM by using ordered target statistics for high-cardinality categorical features, preventing models from memorizing rare categories. It also auto-generates categorical feature interactions, reducing manual feature engineering while improving generalization.

‚ö°Ô∏è

### Quick Links

[### Support for Crunchy Hardened PostgreSQL Ends Soon (4 minute read)](https://www.percona.com/blog/support-for-crunchy-hardened-postgresql-ends-soon-dont-get-caught-off-guard/?utm_source=tldrdata)

Regulated sectors must plan migrations before April 2026 to avoid compliance and patching gaps.

[### Scaling DuckDB in the Cloud with MotherDuck CEO Jordan Tigani (65 minute podcast)](https://www.youtube.com/watch?v=wIOYAIgPdqw&amp;utm_source=tldrdata)

MotherDuck is a cloud service for DuckDB that scales to zero, isolates tenants per user, and supports hybrid execution that can split queries across local and cloud data.

## Curated deep dives, tools and trends in big data, data science and data engineering üìä

Subscribe

Join 400,000 readers for [one daily email](/api/latest/data)

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/data/advertise)

Timestamp: 1765811390