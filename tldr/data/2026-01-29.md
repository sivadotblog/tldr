OpenAI‚Äôs Scaled Database üìà, LinkedIn‚Äôs Context for Agents üß†, Context Beats Automation üß©

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR Data 2026-01-29

## OpenAI‚Äôs Scaled Database üìà, LinkedIn‚Äôs Context for Agents üß†, Context Beats Automation üß©

üì±

### Deep Dives

[### Scaling PostgreSQL to power 800 million ChatGPT users (15 minute read)](https://openai.com/index/scaling-postgresql/?utm_source=tldrdata)

OpenAI scaled PostgreSQL to handle millions of QPS for 800 million users using one primary and ~50 read replicas, plus heavy use of query optimization, pooling, caching, and workload isolation. Write-heavy traffic is being moved to sharded systems like CosmosDB, with cascading replication and further architectural changes planned to extend scalability.

[### The AI Evolution of Graph Search at Netflix: From Structured Queries to Natural Language (13 minute read)](https://netflixtechblog.com/the-ai-evolution-of-graph-search-at-netflix-d416ec5b1151?gi=469a15a19643&amp;source=rss----2615bd06b42e---4&amp;utm_source=tldrdata)

Netflix shifted to advanced AI techniques for its graph-based search system, including dense vector embeddings for semantic similarity search, transformer-based models for query understanding and ranking, multimodal signals, and real-time graph traversals, to dramatically improve recall, relevance, personalization, and handling of complex/ambiguous queries.

[### Contextual Agent Playbooks and Tools: How LinkedIn Gave AI Coding Agents Organizational Context (8 minute read)](https://www.linkedin.com/blog/engineering/ai/contextual-agent-playbooks-and-tools-how-linkedin-gave-ai-coding-agents-organizational-context?utm_source=tldrdata)

LinkedIn's Contextual Agent Playbooks & Tools (CAPT) is a framework that equips AI coding agents with deep organizational context. Built on Model Context Protocol (MCP), CAPT provides agents with safe, standardized access to internal tools and composable "playbooks" (Jinja2-templated workflows that encode institutional knowledge as reusable step-by-step instructions), allowing dynamic chaining, reduced manual toil, and high developer adoption.

üöÄ

### Opinions & Advice

[### Apache Iceberg and the Catalog Layer (53 minute podcast)](https://roundup.getdbt.com/p/apache-iceberg-and-the-catalog-layer?utm_source=tldrdata)

The Iceberg catalog layer is the core metadata system that handles table discovery, conflict resolution, concurrency control, access governance, and cross-engine interoperability across Spark, Flink, Trino, Snowflake, and more. Modern REST-based catalogs like Apache Polaris enable pluggable, multi-cloud, vendor-neutral lakehouse architectures.

[### AI Trends Reshaping Data Engineering in 2026 (7 minute read)](https://www.alibabacloud.com/blog/ai-trends-reshaping-data-engineering-in-2026_602816?utm_source=tldrdata)

Key AI trends reshaping data engineering in 2026 include converging analytical and operational stacks to cut latency and costs, shifting to streaming-first real-time processing to tackle data quality issues, turning unstructured data into AI-ready assets with embeddings and vector search, evolving from prompt engineering to durable context engineering for institutional knowledge, and redesigning infrastructure for the massive recursive workloads of autonomous AI agents.

[### Why We've Tried to Replace Data Analytics Developers Every Decade Since 1974 (15 minute read)](https://blog.rittmananalytics.com/why-weve-tried-to-replace-data-analytics-developers-every-decade-since-1974-5c0de5a05088?utm_source=tldrdata)

The data industry has repeatedly attempted to eliminate the need for data analytics/BI professionals through new tools. Yet, the fundamental complexity of turning raw business data into actionable insights requires human expertise in understanding context, modeling data accurately, handling transformations, ensuring governance, and iterating with business users.

üíª

### Launches & Tools

[### Custom DuckDB Wasm builds for Cloudflare Workers (4 minute read)](https://tobilg.com/posts/custom-duckdb-wasm-builds-for-cloudflare-workers/?utm_source=tldrdata)

Ducklings enables full DuckDB SQL execution (JOINs, aggregation, and remote Parquet/CSV/JSON queries) directly within Cloudflare Workers, eliminating server/database dependencies and cold-start latency. Leveraging Asyncify, the package bridges DuckDB's synchronous HTTP file system with Workers' async fetch() API. The minimal WASM build (~9.6 MB gzipped) includes httpfs, Parquet, and JSON support, allowing edge workloads such as analytics, ETL, and dynamic SQL APIs with low-latency, global serverless deployment. Memory is limited to 128 MB, and only static extensions are supported.

[### Lance for Embeddings (vector database) (6 minute read)](https://dataengineeringcentral.substack.com/p/lance-for-embeddings-vector-database?utm_source=tldrdata)

Lance offers a lightweight, file-based storage solution optimized for AI workloads, particularly embedding and vector storage, eliminating the complexity and operational overhead of traditional vector databases. The format integrates seamlessly with modern data tools like DuckDB and LangChain, supports similarity search natively, and requires only a basic pip install for setup.

[### Open Semantic Interchange (OSI) Updates: Specification Now Live, New Working Group Members and More (3 minute read)](https://www.snowflake.com/en/blog/open-semantic-interchanges-specs-finalized/?utm_source=tldrdata)

OSI is a new open-source standard for sharing data semantics, so definitions like metrics and dimensions work consistently across tools and AI systems. The spec is live, the partner ecosystem is growing, and the project will move to foundation-led governance.

[### SQLFluff 4.0 Released (8 minute read)](https://github.com/sqlfluff/sqlfluff/releases/tag/4.0.0?utm_source=tldrdata)

SQLFluff 4.0 introduces an optional Rust-based parser and lexer for significant performance gains on large projects, with plans to make it the default in v5.0. The release also updates dbt support, fixes bugs, and expands SQL dialect coverage across engines like Postgres, BigQuery, DuckDB, and T-SQL.

üéÅ

### Miscellaneous

[### The private cloud returns for AI workloads (5 minute read)](https://www.infoworld.com/article/4122336/the-private-cloud-returns-for-ai-workloads.html?utm_source=tldrdata)

Enterprises aggressively adopting public cloud for generative AI are facing unexpected costs, operational risks, and data proximity challenges due to spiky, GPU-intensive workloads and unpredictable scaling. AI-driven architectures expose inefficiencies‚Äîlike persistent metered pricing and multi-service dependency chains‚Äîmaking private cloud deployments near operational centers financially and operationally preferable for inference and retrieval, while using public cloud for burst training.

[### Demystifying evals for AI agents (19 minute read)](https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents?utm_source=tldrdata)

Rigorous, automated evaluation frameworks are crucial for scalable, reliable AI agent development, transforming reactive debugging into proactive, metric-driven iteration. Effective agent evals combine code-, model-, and human-based grading across multidimensional tasks (e.g., coding, research, conversation, and GUI operations) using industry benchmarks and custom test suites. Quantitative methods like pass@k and pass^k provide nuanced performance metrics. Early and continuous investment in eval infrastructure accelerates delivery, prevents regressions, and creates actionable quality metrics. Open-source tools like Harbor, Promptfoo, and LangSmith lower adoption barriers.

‚ö°Ô∏è

### Quick Links

[### State of Airflow 2026: The Orchestration Layer is Uniting Data, AI, and Enterprise Growth (6 minute read)](https://www.astronomer.io/blog/state-of-airflow-2026?utm_source=tldrdata)

26% of all Airflow users (and about half of Astronomer's) already upgraded to Airflow 3, less than a year post-release.

[### Kafka Dead Letter Queue Triage: Debugging 25,000 Failed Messages (5 minute read)](https://skey.uk/post/kafka-dead-letter-queue-troubleshooting-guide/?utm_source=tldrdata)

A practical guide to turning DLQs from silent data graves into early-warning systems for resilient streaming pipelines.

## Curated deep dives, tools and trends in big data, data science and data engineering üìä

Subscribe

Join 400,000 readers for [one daily email](/api/latest/data)

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/data/advertise)

Timestamp: 1769699710