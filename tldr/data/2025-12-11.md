IBM to Acquire Confluent üí∏, Deterministic Context Wins ‚öôÔ∏è, Hudi Streaming Turbocharged üöÄ

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR Data 2025-12-11

## IBM to Acquire Confluent üí∏, Deterministic Context Wins ‚öôÔ∏è, Hudi Streaming Turbocharged üöÄ

üì±

### Deep Dives

[### Apache Hudi 1.1 Deep Dive: Optimizing Streaming Ingestion with Apache Flink (5 minute read)](https://hudi.apache.org/blog/2025/12/10/apache-hudi-11-deep-dive-optimizing-streaming-ingestion-with-flink?utm_source=tldrdata)

Apache Hudi 1.1 delivers major streaming ingestion performance gains for petabyte-scale workloads by optimizing Flink integration, reducing SerDe overhead, and eliminating record-level byte copying. Benchmarks show up to 25% throughput improvements and significant reductions in latency and GC pressure, especially with string-heavy schemas. These enhancements are fully backward-compatible.

[### Apache Spark Optimizations (23 minute read)](https://blog.flipkart.tech/apache-spark-optimisations-c3464f71bd38?utm_source=tldrdata)

Flipkart slashed a 35+ hour Spark ETL job on 7TB of data by 36% to 20‚Äì22 hours using repartitioning, high parallelism, AQE skew handling, Kryo+Snappy compression, off-heap memory, dynamic allocation, and smart caching/checkpointing. The optimizations eliminated spills, OOMs, stragglers, and excessive shuffle I/O while dramatically improving cluster efficiency.

[### The Art Behind Better AI: How We Achieved a 46% Speed Boost and 23√ó Cost Reduction (5 minute read)](https://www.wix.engineering/post/the-art-behind-better-ai-how-we-achieved-a-46-speed-boost-and-23-cost-reduction?utm_source=tldrdata)

Wix boosted its AI scheduling assistant by adding a deterministic context-engineering pipeline that normalizes inputs, ranks contacts by interaction history, and cuts tokens by 96% with concise formatting. This resulted in a 46% faster response time (1.79s vs. baseline with Gemini Flash 2.0), a 23√ó cost reduction per request, and enabled switching to cheaper models like Gemini Flash 2.0 over GPT-4.1.

[### Improving MySQL Cluster Uptime: Making MGR Viable at Scale (8 minute read)](https://www.uber.com/blog/improving-mysql-cluster-uptime-part2/?utm_source=tldrdata)

Uber replaced manual, error-prone MySQL failovers with MySQL Group Replication using a 3-node single-primary consensus group plus async read replicas, backed by a custom orchestrator for automated onboarding, rebalancing, and recovery. This delivered near-instant automatic failovers, strict consistency, zero split-brain risk, and drastically reduced downtime with only minor performance overhead at massive scale.

üöÄ

### Opinions & Advice

[### What 10 PB of Cold Data Really Costs in AWS, GCP, Azure vs Tape Over 20 Years (5 minute read)](https://hackernoon.com/what-10-pb-of-cold-data-really-costs-in-aws-gcp-azure-vs-tape-over-20-years?utm_source=tldrdata)

For archival datasets of 10 PB with minimal access (2.5% monthly) over 5-20 years, cloud cold storage results in total costs from $1.64M (5 years) to $6.58M (20 years), while a tape-backed object storage solution (including cloud egress fee) reduces total TCO to $1.4M (5 years) to $4.11M (20 years), following a "flattening". Operational workloads still benefit from cloud agility, but for cold data, tape-based solutions are financially and strategically superior.

[### AI Memory is Really a Database Problem (7 minute read)](https://www.infoworld.com/article/4101981/ai-memory-is-just-another-database-problem.html?utm_source=tldrdata)

AI agent memory must be treated with the same rigor as enterprise databases, incorporating firewalls, access controls, row-level security, and full auditability. Current approaches‚Äîoften unmanaged vector stores or in-memory caches‚Äîcreate significant attack surfaces through memory poisoning, tool misuse, and privilege creep. Integrating agent memory into governed, auditable data infrastructure ensures data lineage, lifecycle management, and robust security.

[### You Gotta Push If You Wanna Pull (5 minute read)](https://www.morling.dev/blog/you-gotta-push-if-you-wanna-pull/?utm_source=tldrdata)

Efficient ‚Äúpull‚Äù queries that feel instant require precomputed materialized views that handle performance, joins, and the exact data shape the application needs. These views stay fresh in real time by continuously pushing only incremental changes from the source (via CDC tools like Debezium + Flink, or modern IVM systems like Materialize and pg\_ivm), delivering the best of both worlds: zero recomputation cost and immediate results on every pull.

üíª

### Launches & Tools

[### Your AI might be ready, but is your data? (Sponsor)](https://www.thoughtworks.com/insights/whitepapers/beyond_platforms_and_cloud_modernizing_data_for_rapid_value_creation?utm_source=media-buy&amp;utm_medium=paid-media&amp;utm_campaign=data_rp-gl-pspt_tldr-rapidvaluecreation_2025-12)

AI is moving at 10x speed, but most organizations' data quality is improving at 1x. Modernizing that gap is where leaders win or lose. [This whitepaper](https://www.thoughtworks.com/insights/whitepapers/beyond_platforms_and_cloud_modernizing_data_for_rapid_value_creation?utm_source=media-buy&utm_medium=paid-media&utm_campaign=data_rp-gl-pspt_tldr-rapidvaluecreation_2025-12) by Thoughtworks shows how modernizing that gap unlocks real, scalable value.

[### Agentic Postgres: Postgres for Agentic Apps with Fast Forking and AI-Ready Features (2 minute read)](https://www.infoq.com/news/2025/12/agentic-postgres-fast-forking/?utm_source=tldrdata)

Agentic Postgres is a Postgres extension built for AI agents that adds sub-second copy-on-write forking (via Fluid Storage), native BM25 and high-performance vector search, and an integrated MCP server for natural-language schema management and prompt-driven operations. It enables instant, isolated sandboxes on live production data, dramatically speeding up agentic workflows, safe experimentation, and migrations while solving cloud-Postgres latency and scaling pain points.

[### The Chameleon Architecture: Mastering Schema Evolution with Apache Hudi (4 minute read)](https://medium.com/@shaiksameer0045/the-chameleon-architecture-mastering-schema-evolution-with-apache-hudi-446da1a2f0c6?utm_source=tldrdata)

The Chameleon Architecture uses Apache Hudi's native schema evolution capabilities to handle dynamic data structures in lakehouses, allowing seamless addition of columns, type promotions, and reordering without downtime or rebuilds. By reconciling schemas during ingestion and injecting nulls for missing fields in older Parquet files, it ensures backward compatibility and agility while addressing challenges like mixed-schema reads.

[### IBM to Acquire Confluent to Create Smart Data Platform for Enterprise Generative AI (5 minute read)](https://newsroom.ibm.com/2025-12-08-ibm-to-acquire-confluent-to-create-smart-data-platform-for-enterprise-generative-ai?utm_source=tldrdata)

IBM is acquiring Confluent for $11 billion to build a unified ‚Äúsmart data platform‚Äù that combines real-time streaming, hybrid-cloud data flow, and AI readiness. This move signals a shift toward streaming-native, low-latency infrastructures as the backbone for enterprise generative AI and analytics.

üéÅ

### Miscellaneous

[### Read Excel Files (10 minute read)](https://learn.microsoft.com/en-us/azure/databricks/query/formats/excel?utm_source=tldrdata)

A beta feature in Azure Databricks can directly read and stream Excel files with built-in Spark and SQL support, automatically inferring schema and data types. It supports sheets, ranges, and Auto Loader, without needing external libraries.

[### Donating the Model Context Protocol and Establishing the Agentic AI Foundation (4 minute read)](https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation?utm_source=tldrdata)

Anthropic donated Model Context Protocol (MCP) to the newly created Agentic AI Foundation (AAIF) under Linux Foundation, putting it alongside contributions such as goose (from Block) and AGENTS.md (from OpenAI). The move ensures MCP becomes a vendor-neutral, community-governed standard for linking AI agents to external tools, data, and services that promote interoperability, open governance, and long-term sustainability. This establishes a shared, open foundation for agentic AI: a stable infrastructure to connect models, tools, data, and applications across platforms without vendor lock-in.

‚ö°Ô∏è

### Quick Links

[### Announcing DuckDB 1.4.3 LTS (2 minute read)](https://duckdb.org/2025/12/09/announcing-duckdb-143.html?utm_source=tldrdata)

Windows Arm64 support and native Python wheels bring a 24% performance boost to DuckDB on modern laptops.

[### The Release of Apache Polaris 1.3.0 (Incubating): Improvements to catalog federation, handling non-Apache Iceberg datasets, and more (4 minute read)](https://www.dremio.com/blog/the-release-of-apache-polaris-1-3-0-incubating-improvements-to-catalog-federation-handling-non-apache-iceberg-datasets-and-more/?utm_source=tldrdata)

Polaris 1.3.0 adds generic table support and fine-grained IAM controls, strengthening multi-engine governance.

## Curated deep dives, tools and trends in big data, data science and data engineering üìä

Subscribe

Join 400,000 readers for [one daily email](/api/latest/data)

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/data/advertise)

Timestamp: 1765465695