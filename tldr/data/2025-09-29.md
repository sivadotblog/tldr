Fivetran Eyes dbt Labs üéØ, Cloudflare Launches Data Platform ‚òÅÔ∏è, PostgreSQL 18 üöÄ

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# Improve your data knowledge in 5 min 2025-09-29

## Fivetran Eyes dbt Labs üéØ, Cloudflare Launches Data Platform ‚òÅÔ∏è, PostgreSQL 18 üöÄ

üì±

### Deep Dives

[### R2 SQL: A Deep Dive Into Our New Distributed Query Engine (12 minute read)](https://blog.cloudflare.com/r2-sql-deep-dive/?utm_source=tldrdata)

Cloudflare has launched R2 SQL, a serverless, Apache DataFusion-based query engine that enables low-latency SQL analytics over petabyte-scale datasets stored in R2 object storage using Apache Iceberg. R2 SQL leverages multi-layer metadata pruning and distributed execution across Cloudflare's global network, drastically reducing read I/O and compute waste by streaming prioritized row-group work units to scalable DataFusion query workers. R2 SQL is available in open beta.

[### Building a Resilient Data Platform with Write-Ahead Log at Netflix (13 minute read)](https://netflixtechblog.com/building-a-resilient-data-platform-with-write-ahead-log-at-netflix-127b6712359a?utm_source=tldrdata)

Netflix faced challenges like data loss, corruption, system entropy, multi-partition updates, cross-region replication, and scalable retry mechanisms in its data platform. To address these, it built a generic Write-Ahead Logging (WAL) system using Kafka for messaging, SQS for delayed queues, and durable storage for complex scenarios featuring a simple API for writing changes with pluggable queues, automatic scaling, and dead letter queues.

[### Building a Next-Generation Key-Value Store at Airbnb (8 minute read)](https://medium.com/airbnb-engineering/building-a-next-generation-key-value-store-at-airbnb-0de8465ba354?utm_source=tldrdata)

Airbnb's original Mussel v1 key-value store struggled with operational complexity, scalability hotspots, and limited consistency amid growing needs for real-time fraud detection, personalization, dynamic pricing, and massive data ingestion. Mussel v2 addresses these with a NewSQL backend, Kubernetes-native control plane, dynamic range sharding, namespace tenancy, and quota enforcement, enabling automated scaling and options for immediate or eventual consistency.

[### Haydex: From Zero to 178,600,000,000 Rows a Second in 30 Days (20 minute read)](https://axiom.co/blog/building-haydex?utm_source=tldrdata)

Haydex's development showcases the importance of I/O architecture and distributed redesign in achieving exceptional data processing speeds, reaching up to 673 billion rows per second. Key insights include the shift to large reads, profiler-driven optimizations that revealed hidden performance issues, and the synergistic effect of compound optimizations that significantly enhanced indexing efficiency. Ultimately, the transition from a flawed initial design to a robust version underscores the necessity of adapting to practical constraints in engineering solutions.

üöÄ

### Opinions & Advice

[### What ‚ÄúSupporting Our AI Overlords‚Äù and ‚ÄúSemantic Spacetime‚Äù Tell Us About the Future of Data Infrastructure (9 minute read)](https://www.dataengineeringweekly.com/p/what-supporting-our-ai-overlords?utm_source=tldrdata)

Adoption of agent-first data systems requires rethinking data infrastructure to enable rapid, speculative, and semantic querying, contrasting sharply with current human-centered, schema-first warehouses. Key shifts include probe optimizers for handling thousands of overlapping agent requests, native support for cheap branching/rollback, and modeling grounded in universal semantic primitives (events, things, concepts, with NEAR/LEADS TO/CONTAINS/EXPRESSES relations). ETL, query optimization, and concurrency control must evolve for agent-native workflows, making flexibility, approximation, and reasoning foundational instead of exceptions.

[### DuckDB vs Polars. Wait. DuckDB and Polars (5 minute read)](https://www.confessionsofadataguy.com/duckdb-vs-polars-wait-duckdb-and-polars/?utm_source=tldrdata)

Choosing between DuckDB and Polars isn't a binary decision. Just select the tool that aligns with your specific requirements: DuckDB excels with simple installation and SQL-powered database features for versatile analytics on diverse sources like DataFrames and S3 files, whereas Polars delivers high-speed DataFrame processing without database capabilities.

üíª

### Launches & Tools

[### Don't miss PyTorch Conference, October 22‚Äì23 in San Francisco! (Sponsor)](https://hubs.la/Q03K-WSw0?utm_source=tldrdata)

Join 2,500+ AI engineers and researchers for 6 tracks, 3 co-located summits, training + certification, a Startup Showcase, and MORE! Learn, connect, and shape the future of open source AI. [Learn more + view the full schedule.](https://hubs.la/Q03K-WSw0) Save 50% off your attendee pass with code TLDRDATA. [Register Today!](https://hubs.la/Q03KX2jj0)

[### Announcing the Cloudflare Data Platform: Ingest, Store, and Query Your Data Directly on Cloudflare (8 minute read)](https://blog.cloudflare.com/cloudflare-data-platform/?utm_source=tldrdata)

Cloudflare has unveiled a fully managed Data Platform that features R2 Data Catalog (an Apache Iceberg-compatible catalog), Cloudflare Pipelines for event ingestion and SQL-based transformation, and R2 SQL, a distributed SQL engine for petabyte-scale analytics directly on R2 object storage. The platform supports open standards, integration with external engines like DuckDB and Spark, and eliminates data egress fees. Automated compaction in R2 Data Catalog ensures optimized query performance, while serverless, usage-based pricing and global scalability substantially reduce operational complexity.

[### Apache Flink CDC 3.5.0 Release Announcement (3 minute read)](https://flink.apache.org/2025/09/26/apache-flink-cdc-3.5.0-release-announcement/?utm_source=tldrdata)

Apache Flink CDC 3.5.0 adds Fluss sink and PostgreSQL source connectors, with stronger schema evolution and fixes for multi-table syncs, date/time precision, and CDC across MySQL, PostgreSQL, and OceanBase to improve real-time analytics and Lakehouse pipelines.

[### PostgreSQL 18 Released! (5 minute read)](https://www.postgresql.org/about/news/postgresql-18-released-3142/?utm_source=tldrdata)

PostgreSQL 18 introduces a new asynchronous I/O subsystem, delivering up to 3x storage read performance improvement and enhanced index utilization for faster queries. Major version upgrades are now less disruptive thanks to carryover planner statistics, parallelized pg\_upgrade, and accelerated post-upgrade performance. Key features include virtual generated columns, UUIDv7 for better indexing, OAuth 2.0 authentication, and expanded hardware acceleration. Improved replication, vacuum strategies, and comprehensive EXPLAIN diagnostics further optimize reliability and operational efficiency.

[### What's New in PostgreSQL 18 - A Developer's Perspective (5 minute read)](https://www.bytebase.com/blog/what-is-new-in-postgres-18-for-developer/?utm_source=tldrdata)

PostgreSQL 18 introduces significant features for data engineers, including native support for UUIDv7, streamlining primary key management. It also adds VIRTUAL generated columns, which optimize storage and computation by calculating values on read rather than write.

üéÅ

### Miscellaneous

[### Report: Fivetran in Talks with dbt Labs Over Multibillion-Dollar Big-Data Merger (4 minute read)](https://siliconangle.com/2025/09/28/report-fivetran-talks-dbt-labs-multibillion-dollar-big-data-merger/?utm_source=tldrdata)

Fivetran is in advanced talks to acquire dbt Labs, aiming to enhance its big data integration capabilities by combining Fivetran's data movement strengths with dbt's analytics expertise. This potential merger could streamline data processing, reduce fragmentation, and bolster AI-driven data preparation, positioning both companies as key players in the evolving data landscape.

[### Monitor Your Data Pipelines with Airflow Lineage (6 minute read)](https://www.datadoghq.com/blog/airflow-data-lineage-monitoring/?utm_source=tldrdata)

Apache Airflow's complex data pipelines make tracking data flow, errors, and compliance challenging, such as pinpointing upstream causes of failures or assessing downstream impacts on dashboards and ML models. Datadog's Data Observability integrates via OpenLineage to collect and visualize lineage graphs, enabling quick root-cause triage, reduced MTTR, and column-level insights for data quality and PII compliance.

‚ö°Ô∏è

### Quick Links

[### Postgres 18: OLD and NEW Rows in the RETURNING Clause (6 minute read)](https://www.crunchydata.com/blog/postgres-18-old-and-new-in-the-returning-clause?utm_source=tldrdata)

NEW and OLD row access in Postgres 18's RETURNING clause simplifies change capture and auditing without trigger hacks.

[### dbt-blueprint (GitHub Repo)](https://github.com/Alex-Teodosiu/dbt-blueprint?utm_source=tldrdata)

A GitHub blueprint that demonstrates dbt Core for a Databricks-based data warehouse.

## Curated deep dives, tools and trends in big data, data science and data engineering üìä

Subscribe

Join 308,008 readers for [one daily email](/api/latest/data)

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/data/advertise)

Timestamp: 1759191971