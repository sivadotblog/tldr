Universal Ownership üåê, Salesforce‚Äôs Open Lakehouse üßä, MariaDB Vector Search üîç

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR Data 2025-06-23

## Universal Ownership üåê, Salesforce‚Äôs Open Lakehouse üßä, MariaDB Vector Search üîç

üì±

### Deep Dives

[### Scaling our Observability Platform Beyond 100 Petabytes by Embracing Wide Events and Replacing OTel (32 minute read)](https://clickhouse.com/blog/scaling-observability-beyond-100pb-wide-events-replacing-otel?utm_source=tldrdata)

LogHouse scaled its observability platform from 19PB to 100PB and 500 trillion rows by replacing OpenTelemetry with a native ClickHouse-to-ClickHouse pipeline using SysEx. SysEx is a purpose-built exporter that reduces CPU usage by 90% and enables high-fidelity, wide-event telemetry. The integration of HyperDX's ClickHouse-native UI further enhances log and trace exploration, supporting real-time debugging and analytics at massive scale.

[### RocksDB 101: Optimizing Stateful Streaming in Apache Spark with Amazon EMR and AWS Glue (10 minute read)](https://aws.amazon.com/blogs/big-data/rocksdb-101-optimizing-stateful-streaming-in-apache-spark-with-amazon-emr-and-aws-glue/?utm_source=tldrdata)

Apache Spark Structured Streaming now supports RocksDB as a high-performance state store, offering a scalable, off-heap solution for stateful workloads with large or complex state data. RocksDB integration mitigates JVM memory pressure and GC overhead, enables efficient checkpointing (with changelog checkpointing in EMR 7.0/Glue 5.0), and supports disk spillover for robust fault tolerance. Data platform engineers gain improved reliability and scale for demanding real-time applications but must proactively manage memory/disk settings for optimal performance and cost control.

[### A Reality Check on DeepSeek's Distributed File System Benchmarks (11 minute read)](https://maknee.github.io/blog/2025/3FS-Performance-Journal-2/?utm_source=tldrdata)

Benchmarking 3FS's results to hardware baselines (e.g., SSDs and network limits) can help identify inefficiencies across AI training, GraySort, and KV cache tasks without extensive profiling. This ‚Äúperformance reality check‚Äù reveals that 3FS only utilizes 73% of the 9 TB/s network capacity, indicating a network bottleneck and potential optimization paths like upgrading NICs.

[### Inside Data Cloud's Open Lakehouse: 4M Tables and 50PB ‚Äì Enabled by Apache Iceberg (8 minute read)](https://engineering.salesforce.com/inside-data-clouds-open-lakehouse-4m-tables-and-50pb-powered-by-apache-iceberg/?utm_source=tldrdata)

Salesforce reengineered its Data Cloud Lakehouse to power AI-driven workloads at unprecedented enterprise scale, supporting 4 million Apache Iceberg tables and 50 petabytes of data. Transitioning from Hive Metastore to an open, multi-engine architecture (Spark, Hyper, and Trino) enabled schema evolution, ACID compliance, and real-time incremental processing through event-driven storage optimization and change data capture.

üöÄ

### Opinions & Advice

[### Why Parquet Is the Go-To Format for Data Engineers (10 minute read)](https://luminousmen.com/post/why-parquet-is-the-goto-format-for-data-engineers/?utm_source=tldrdata)

Apache Parquet's columnar format stores data in row groups, column chunks, and pages, using dictionary and run-length encodings with footer metadata to enable predicate pushdown and column pruning for faster queries. Its writing process creates row groups with compressed column chunks and metadata, while reading leverages parallelism and filters to selectively access data, supporting efficient analytics in data lakes and warehouses.

[### Pursuit of Universal Ownership at LinkedIn (7 minute read)](https://www.linkedin.com/blog/engineering/infrastructure/-pursuit-of-universal-ownership-at-linkedin?utm_source=tldrdata)

LinkedIn's ‚ÄúCrews‚Äù model solves unclear system ownership by assigning every asset to a stable team with a clear manager and on-call responsibility. This structure improves resilience during reorgs, enables clean escalation paths, and connects related assets across teams into larger ‚ÄúProducts‚Äù for better visibility and coordination.

üíª

### Launches & Tools

[### Keep your presentations up-to-date with this free Chrome extension (Sponsor)](https://www.matik.io/smart-data-sync?utm_source=PaidMedia&amp;utm_medium=newsletter&amp;utm_campaign=sds_june25_launch&amp;utm_content=TLDR_newsletter_June23)

Say goodbye to outdated slides. [Smart Data Sync by Matik](https://www.matik.io/smart-data-sync?utm_source=PaidMedia&utm_medium=newsletter&utm_campaign=sds_june25_launch&utm_content=TLDR_newsletter_June23) lets you embed live charts, tables, and metrics into your presentations‚Äîautomatically updated from Salesforce, Tableau, SQL databases, and more. Save time, stay accurate, and stop sending dashboard links your team never opens. [Get the free Chrome extension](https://www.matik.io/smart-data-sync?utm_source=PaidMedia&utm_medium=newsletter&utm_campaign=sds_june25_launch&utm_content=TLDR_newsletter_June23)

[### Yearly MariaDB LTS Release Integrates Vector Search (4 minute read)](https://www.infoq.com/news/2025/06/mariadb-vector-search/?utm_source=tldrdata)

MariaDB Community Server 11.8 LTS introduces integrated vector search with native indexing and SIMD optimizations, enabling high-performance similarity search for AI/ML workloads such as semantic search and recommendation engines. Additional enhancements include extended Unicode support, improved temporal tables for auditing, and an 80-year TIMESTAMP range extension without data conversion.

[### Daft (GitHub Repo)](https://github.com/Eventual-Inc/Daft?utm_source=tldrdata)

Daft is a distributed data processing engine built in Rust with a Python and SQL interface that supports multimodal data types like images and embeddings. It features intelligent query optimization, seamless S3 integration, and native Ray support for scalable cluster execution. Designed for fast, interactive workflows in the cloud and optimized for modern data use cases.

[### A Data Engineer's Guide to PyIceberg (9 minute read)](https://hackernoon.com/a-data-engineers-guide-to-pyiceberg?utm_source=tldrdata)

PyIceberg enables data engineers to access and manipulate Apache Iceberg tables, supporting read-write-upsert operations and metadata management using lightweight compute engines like PyArrow, Daft, or DuckDB. It simplifies data workflows for small to medium-sized platforms, offering a Python-friendly alternative to JVM-based query engines like Spark, and supports streaming data integration with tools like Tableflow.

[### Ownstats (GitHub Repo)](https://github.com/ownstats/ownstats?utm_source=tldrdata)

Ownstats is a privacy-conscious, serverless web analytics stack built on AWS. It includes a backend for data collection and enrichment (stored in S3), a React frontend powered by DuckDB WASM, and a lightweight JS client for tracking. The setup requires Node 18+, Serverless Framework v3, and AWS credentials.

üéÅ

### Miscellaneous

[### Quacking Through Data: DuckDB's Emerging Ecosystem (19 minute podcast)](https://datastackshow.com/podcast/quacking-through-data-duckdbs-emerging-ecosystem/?utm_source=tldrdata)

Current data storage standards center on Parquet and Iceberg. However, with ongoing challenges in catalog management, there is value in local compute solutions and simplified infrastructure for faster, cost-effective analytics workflows. DuckDB provides a lightweight, local analytics database and a potential caching layer for open table formats.

[### Private Cloud's Comeback: Driving the Enterprise IT Reset (9 minute read)](https://thenewstack.io/private-clouds-comeback-driving-the-enterprise-it-reset/?utm_source=tldrdata)

Enterprises are pivoting to a hybrid cloud strategy, with 93% now leveraging both public and private clouds and 69% repatriating workloads, primarily security-sensitive (51%) and data-intensive (46%), to private environments. Drivers include robust security (cited by 92% of IT leaders), stringent compliance needs, and significantly better cost predictability, with 90% favoring private cloud for financial visibility.

‚ö°Ô∏è

### Quick Links

[### Data Is Risky Business: Sustainability and Resilience in Data Governance (10 minute read)](https://tdan.com/data-is-risky-business-sustainability-and-resilience-in-data-governance/32745?utm_source=tldrdata)

A call to evolve governance programs into living frameworks that survive leadership churn, tech shifts, and regulatory waves.

[### Understanding Application Performance with Roofline Modeling (4 minute read)](https://towardsdatascience.com/understanding-application-performance-with-roofline-modeling/?utm_source=tldrdata)

Roofline charts bridge compute-bandwidth gaps, guiding architects in squeezing every flop from modern hardware.

[### Small is the New Big (3 minute read)](https://joereis.substack.com/p/small-is-the-new-big?utm_source=tldrdata)

Enterprise leaders like Amazon's CEO are openly pushing for leaner organizations powered by AI, moving away from large teams and traditional management structures.

## Curated deep dives, tools and trends in big data, data science and data engineering üìä

Subscribe

Join 308,008 readers for [one daily email](/api/latest/data)

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/data/advertise)

Timestamp: 1750724859