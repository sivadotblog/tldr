Databricks Free Edition üß±, Config-Driven Pipelines üõ†Ô∏è, GCP Serverless Spark ‚ö°

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR Data 2025-06-12

## Databricks Free Edition üß±, Config-Driven Pipelines üõ†Ô∏è, GCP Serverless Spark ‚ö°

üì±

### Deep Dives

[### From Archival to Access: Config-Driven Data Pipelines (10 minute read)](https://www.uber.com/en-FR/blog/from-archival-to-access/?utm_source=tldrdata)

Managing 500+ regulatory reports in HDFS strained storage quotas and made fine-grained retrieval impractical, so Uber developed a config-driven archival framework that automates moving data from hot HDFS to cold S3-based storage to slash operational costs and preserve audit-grade immutability. A complementary trigger-based retrieval pipeline restores only requested partitions back into HDFS with schema mapping and fast multi-part downloads, reducing restore times by 90%. Centralized metadata in MySQL and a self-serve LDAP-secured UI give non-technical users on-demand access, balancing compliance with efficient storage at scale.

[### 7 Operating System Concepts Every LLM Engineer Should Understand (7 minute read)](https://medium.com/wix-engineering/7-operating-system-concepts-every-llm-engineer-should-understand-84ddf0cfb89a?utm_source=tldrdata)

This post presents seven OS concepts that can serve as analogies for LLM engineers to enhance performance and scalability: paging and prompt caching (cache misses like page faults slow down inference); inference‚Äëtask parallelism and allocation, akin to CPU scheduling; system calls parallel function calling in LLMs for structured tasks; file systems align with embedding stores for data retrieval; virtual memory mirrors the LLM's context window, handling data access; system prompts act like the LLM's ‚Äúkernel,‚Äù guiding behavior; and security, isolation, and sandboxing ensure safe model execution, like OS process isolation.

[### How Hierarchical Navigable Small World (HNSW) Algorithms Can Improve Search (5 minute read)](https://redis.io/blog/how-hnsw-algorithms-can-improve-search/?utm_source=tldrdata)

The HNSW (Hierarchical Navigable Small World) algorithm enhances search performance in Redis by efficiently handling high-dimensional vector data for similarity searches. It organizes data into a multi-layered graph, minimizes hops, and reduces distance computations. A study highlighted that HNSW is the fastest across all recall values compared to other ANN algorithms.

üöÄ

### Opinions & Advice

[### The History and Future of the Data Ecosystem (44 minute podcast)](https://roundup.getdbt.com/p/the-history-and-future-of-the-data?utm_source=tldrdata)

From mainframes' early sorting challenges through the rise of ETL, Hadoop, and modern cloud data stacks, entrenched switching costs have kept legacy tools in place despite better alternatives. Generative AI and code-generating agents now threaten to erode those costs by automating migrations and complex workflows, potentially democratizing data infrastructure for non-technical users. As the data ecosystem further disaggregates and AI interfaces gain direct access to real enterprise metadata, the next decade will test incumbents' durability and reshape the total addressable market for analytics and orchestration.

[### Keep Your BI Tool as Dumb as Possible (7 minute read)](https://handsondata.substack.com/p/keep-your-bi-tool-as-dumb-as-possible?utm_source=tldrdata)

Push business logic and data quality upstream into your warehouse or semantic layer to keep BI tools lightweight, interchangeable, and focused solely on visualization. This ‚Äúshift left‚Äù approach simplifies migrations, improves governance, and boosts long-term data reliability across platforms.

[### Just-In-Time Data Modeling (4 minute read)](https://practicaldatamodeling.substack.com/p/just-in-time-data-modeling?utm_source=tldrdata)

Just-in-Time Data Modeling (JITDM) enables data teams to rapidly deliver value by building only the minimum viable models required for immediate business needs, rather than relying on traditional Big Design Up Front (BDUF) methods. Effective JITDM requires standardized naming, clear documentation, and disciplined promotion of reusable models to production, balancing agility with long-term data integrity.

[### Beyond Code: APIs as the Next OSS Battleground (8 minute read)](https://redmonk.com/sogrady/2025/06/09/open-source-apis/?utm_source=tldrdata)

The Supreme Court's ruling in Google v. Oracle clarified that API reimplementations can constitute fair use, significantly lowering legal risks for competitive API usage and reducing the threat of proprietary API lock-in. This precedent has triggered rising API-centric competition, as seen in the MongoDB-FerretDB dispute, bypassing traditional relicensing tactics aimed at code exclusivity.

üíª

### Launches & Tools

[### Introducing Databricks Free Edition (3 minute read)](https://www.databricks.com/blog/introducing-databricks-free-edition?utm_source=tldrdata)

Databricks Free Edition now gives learners free access to many core data and AI tools previously paywalled, including SQL, data engineering (via Lakeflow), Mosaic AI, dashboards, and collaboration. It also includes AI-assisted coding and all self-paced Databricks Academy courses at no cost, making it a strong platform for those entering the AI and data fields.

[### Mosaic AI Announcements at Data + AI Summit 2025 (5 minute read)](https://www.databricks.com/blog/mosaic-ai-announcements-data-ai-summit-2025?utm_source=tldrdata)

Databricks announced major upgrades to its Mosaic AI stack at the 2025 Data + AI Summit, including Agent Bricks for auto-optimized task-specific agents, MLflow 3.0 with GenAI-focused observability and prompt versioning, and Serverless GPU Compute for effortless training and inference. Other highlights include faster, multi-modal AI Functions in SQL, a cost-efficient Storage-Optimized Vector Search, scalable Model Serving with in-house inference, MCP integration, and the GA release of AI Gateway for unified AI governance and safety.

[### Narwhals (GitHub Repo)](https://github.com/narwhals-dev/narwhals?utm_source=tldrdata)

Narwhals provides a lightweight, extensible compatibility layer for dataframe libraries, enabling developers to write dataframe-agnostic code using a subset of the Polars API. It supports full API compatibility with cuDF, Modin, pandas, Polars, and PyArrow, and lazy-only support for Dask, DuckDB, Ibis, PySpark, and SQLFrame.

[### Google Cloud Serverless for Apache Spark: High-performance, Unified with BigQuery (5 minute read)](https://cloud.google.com/blog/products/data-analytics/introducing-google-cloud-serverless-for-apache-spark-in-bigquery/?utm_source=tldrdata)

Google Cloud has integrated serverless Apache Spark into BigQuery, allowing users to run Spark jobs directly within BigQuery using PySpark or SQL without managing infrastructure. This integration enables seamless data processing, analytics, and machine learning on large datasets with automatic scaling and unified governance.

üéÅ

### Miscellaneous

[### How We Bootstrapped EODHD APIs From a $10 Server to a Global Data Infrastructure (8 minute read)](https://thenewstack.io/how-we-bootstrapped-eodhd-apis-from-a-10-server-to-a-global-data-infrastructure/?utm_source=tldrdata)

EODHD APIs scaled from a $10 server-side project to a 17-server, global financial data infrastructure without venture funding, emphasizing pragmatic architecture and lean operations. Leveraging DigitalOcean, in-DB queues, ClickHouse for analytics, and selective containerization, the team prioritized incremental modernization while battling technical debt.

[### Databricks Free Edition limitations (4 minute read)](https://docs.databricks.com/aws/en/getting-started/free-edition-limitations?utm_source=tldrdata)

Databricks Free Edition is a no-cost, serverless environment for personal and educational use, with strict limitations. Compute is capped to small cluster sizes (e.g., one 2X-Small SQL warehouse and no custom compute or GPUs), and you're limited to five concurrent job tasks, one app, one DLT pipeline per type, and one vector search unit. It lacks support for R, Scala, custom storage, SSO, SCIM, and commercial use. If usage exceeds quotas, compute is disabled for the rest of the day or longer, though data persists.

‚ö°Ô∏è

### Quick Links

[### Cloud Run GPUs, Now GA, Makes Running AI Workloads Easier for Everyone (3 minute read)](https://cloud.google.com/blog/products/serverless/cloud-run-gpus-are-now-generally-available?utm_source=tldrdata)

Cloud Run now supports NVIDIA GPU accelerators (T4, A100) in general availability, enabling developers to deploy serverless containerized workloads at scale without managing GPU infrastructure.

[### Data Science Codes Collection To Improve Your Skill (7 minute read)](https://www.nb-data.com/p/data-science-codes-collection-to?utm_source=tldrdata)

A comprehensive collection of advanced Pandas, NumPy, SQL, and regex code patterns for productivity.

## Curated deep dives, tools and trends in big data, data science and data engineering üìä

Subscribe

Join 308,008 readers for [one daily email](/api/latest/data)

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/data/advertise)

Timestamp: 1749774465