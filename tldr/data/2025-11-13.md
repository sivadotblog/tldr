pgvector‚Äôs Hidden Complexity ‚ö†Ô∏è, Spotify‚Äôs Privacy-First Architecture üîí, State-Driven ML Operations üîÑ

[TLDR](/)

[Newsletters](/newsletters)

[Advertise](https://advertise.tldr.tech/)

[TLDR](/)

# TLDR Data 2025-11-13

## pgvector‚Äôs Hidden Complexity ‚ö†Ô∏è, Spotify‚Äôs Privacy-First Architecture üîí, State-Driven ML Operations üîÑ

üì±

### Deep Dives

[### )](https://hudi.apache.org/blog/2025/11/12/deep-dive-into-hudis-indexing-subsystem-part-2-of-2/?utm_source=tldrdata)

[### How Spotify Built Its Data Platform To Understand 1.4 Trillion Data Points (8 minute read)](https://blog.bytebytego.com/p/how-spotify-built-its-data-platform?utm_source=tldrdata)

Driven by needs for reliability, privacy, and efficiency amid massive growth, Spotify evolved from a single-team Hadoop cluster to a scalable, self-service, cloud-native platform leveraging Kubernetes Operators for automation, built-in privacy safeguards, and Backstage-powered observability with alerts. This new data platform captures 1.4T daily events and runs over 38,000 pipelines.

[### How Klaviyo Built an Unbreakable System for Running Distributed ML Workloads (11 minute read)](https://klaviyo.tech/how-klaviyo-built-an-unbreakable-system-for-running-distributed-ml-workloads-f6ea35567458?utm_source=tldrdata)

Klaviyo's DART Jobs API enables seamless, distributed ML workload orchestration across multi-cluster Kubernetes infrastructures. Leveraging Ray for scalable Python and AI execution, the architecture decouples coordination from execution via a central MySQL-backed state machine and sync services in each cluster, ensuring consistent job state, robust error handling, and strict resource isolation between development and production. Developers benefit from reproducible, rapid iteration with Python and CLI interfaces, while automated infrastructure management abstracts away complexity.

üöÄ

### Opinions & Advice

[### Data Warehouse, Data Lake, Data Lakehouse, Data Mesh: What They Are and How They Differ (15 minute read)](https://luminousmen.com/post/data-warehouse-data-lake-data-lakehouse-data-mesh-what-they-are-and-how-they-differ/?utm_source=tldrdata)

Data Warehouses offer fast, governed analytics on structured data, but are rigid and costly, while Data Lakes enable cheap storage of any data type for ML and exploration, but risk becoming ungoverned swamps. Data Lakehouses unify both with ACID and open formats for mixed workloads, while Data Mesh decentralizes ownership as data products and is ideal for large, mature organizations with strong self-service infrastructure.

[### The Case Against pgvector (13 minute read)](https://alex-jacobs.com/posts/the-case-against-pgvector/?utm_source=tldrdata)

While pgvector makes vector search appear easy by extending PostgreSQL, in production, it has serious gaps: index types (IVFFlat and HNSW) require manual tuning and heavy memory usage, real-time inserts lead to build/rebuild bottlenecks, filtered queries suffer from planner mismatches, and hybrid search needs DIY integration. While pgvector works, it comes at the cost of operational complexity. For most teams, a dedicated vector DB may be the simpler, more reliable route.

[### Colocating Input Partitions with Kafka Streams When Consuming Multiple Topics: Sub-Topology Matters! (4 minute read)](https://medium.com/expedia-group-tech/colocating-input-partitions-with-kafka-streams-when-consuming-multiple-topics-sub-topology-matters-f92da955c905?utm_source=tldrdata)

When consuming two identically partitioned Kafka topics, Kafka Streams may assign same-index partitions to different instances if processed in separate sub-topologies, breaking local cache reuse and triggering duplicate API calls for identical keys. Unify sub-topologies using a shared state store to enforce partition colocation and enable efficient cross-topic coordination without joins, as topology design is critical to distributed behavior in Kafka Streams.

üíª

### Launches & Tools

[### Data teams lose over $21,613 per analyst each year due to inefficient processes (Sponsor)](https://www.getdbt.com/resources/the-analyst-revolution-unlocking-tomorrows-ai-initiatives?utm_medium=paid-email&amp;utm_source=tldr_&amp;utm_campaign=q4-2026_tldr-newsletters_cv&amp;utm_content=_newsletter1___&amp;utm_term=all_all__)

dbt Labs [surveyed 510 analysts](https://www.getdbt.com/resources/the-analyst-revolution-unlocking-tomorrows-ai-initiatives?utm_medium=paid-email&utm_source=tldr_&utm_campaign=q4-2026_tldr-newsletters_cv&utm_content=_newsletter1___&utm_term=all_all__) to see where analysts are actually spending their time (spoiler: less than 25% is spent on actual analysis). Learn why more than half of analysts use AI tools outside approved systems ‚Äî and what they need to go from busywork to getting things done. If you are tired of spending more time fixing data than analyzing it, this report will show you what needs to change. [Read the report](https://www.getdbt.com/resources/the-analyst-revolution-unlocking-tomorrows-ai-initiatives?utm_medium=paid-email&utm_source=tldr_&utm_campaign=q4-2026_tldr-newsletters_cv&utm_content=_newsletter1___&utm_term=all_all__)

[### The Delta Join in Apache Flink: Architectural Decoupling for Hyper-Scale Stream Processing (20 minute read)](https://www.alibabacloud.com/blog/the-delta-join-in-apache-flink-architectural-decoupling-for-hyper-scale-stream-processing_602645?utm_source=tldrdata)

Delta Join (FLIP‚Äê486) decouples state from streaming joins by routing lookups to external storage rather than retaining all historical data in Flink's checkpointed state. This enables production users to eliminate Terabytes of join state, cut compute costs by an order of magnitude, and dramatically increase recovery speed. The trade-off: you accept external lookup latency in exchange for scalability and operational resilience.

[### What's New in Dash 3.3.0 (7 minute read)](https://plotly.com/blog/whats-new-dash-3-3-0/?utm_source=tldrdata)

Dash 3.3.0 brings major upgrades for day-to-day data app development: fully customizable developer tools, optional and hidden callbacks for cleaner logic, and a new Patch API for fast, surgical client-side figure updates without full re-renders. You can build and share your own dev-tool plugins, profile callbacks, and integrate custom React components directly into the debugging workflow. The release also adds Python 3.14 support and encourages migration from Dash Table to Dash Ag Grid for richer, more performant data grids.

[### BigQuery Under the Hood: How Google Brought Embeddings to Analytics (5 minute read)](https://cloud.google.com/blog/products/data-analytics/the-story-of-bigquery-vector-search/?utm_source=tldrdata)

Google's BigQuery vector search democratizes AI-driven similarity searches by natively embedding vector capabilities into its serverless data platform, allowing users to generate, index, and query embeddings. BigQuery vector search is now enhanced with TreeAH (ScaNN-based) for high-throughput batch tasks, async index training, stored columns for prefiltering, and partitioned indexes to skip irrelevant data.

üéÅ

### Miscellaneous

[### Do You Really Need GraphRAG? A Practitioner's Guide Beyond the Hype (15 minute read)](https://towardsdatascience.com/do-you-really-need-graphrag-a-practitioners-guide-beyond-the-hype/?utm_source=tldrdata)

GraphRAG adds entity and relation-aware reasoning on top of traditional RAG, unlocking cross-document queries, explainability, and massive search-space reduction. However, it comes at a real cost in complexity. GraphRAG is justified for long or relational documents (e.g., investigations and medical cases) but is overkill for independent texts. Start with a star-graph schema, expand iteratively, use graphs as classifiers, not responders, and control semantic fallbacks to avoid hallucinated links.

‚ö°Ô∏è

### Quick Links

[### What Does the End of GIL Mean for Python? (5 minute read)](https://www.kdnuggets.com/what-does-the-end-of-gil-mean-for-python?utm_source=tldrdata)

Python is removing the Global Interpreter Lock (GIL) through PEP 703, enabling true parallel processing across CPU cores.

[### PostgreSQL 18: More Performance with Index Skip Scans (3 minute read)](https://www.cybertec-postgresql.com/en/postgresql-18-more-performance-with-index-skip-scans/?utm_source=tldrdata)

PostgreSQL 18's index skip scans automatically optimize composite B-tree queries by skipping non-qualifying leading column values, jumping directly to the next group after processing matching rare values, delivering up to 100x speedups (66 ms ‚Üí 0.6 ms) in low-cardinality scenarios.

## Curated deep dives, tools and trends in big data, data science and data engineering üìä

Subscribe

Join 400,000 readers for [one daily email](/api/latest/data)

[Privacy](/privacy)[Careers](https://jobs.ashbyhq.com/tldr.tech)[Advertise](/data/advertise)

Timestamp: 1763132483